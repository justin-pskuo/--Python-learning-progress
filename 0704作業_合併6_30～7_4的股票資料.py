# -*- coding: utf-8 -*-
"""7/4ä½œæ¥­-åˆä½µ6/30ï½7/4çš„è‚¡ç¥¨è³‡æ–™

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dpMe5shvEZbFiKp6kD9FiOkLVuhGosVs

# Task
è«‹ä½¿ç”¨ Python ç¨‹å¼ç¢¼ï¼Œä¸‹è¼‰ä¸¦åˆä½µ 2024 å¹´ 6 æœˆ 30 æ—¥è‡³ 2024 å¹´ 7 æœˆ 4 æ—¥çš„è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€æ¯æ—¥æ”¶ç›¤è¡Œæƒ…ï¼ˆå…¨éƒ¨ï¼‰è³‡æ–™ï¼Œå°‡åˆä½µå¾Œçš„è³‡æ–™å„²å­˜ç‚ºä¸€å€‹ pandas DataFrameï¼Œä¸¦ä½¿ç”¨ `df.info()` é¡¯ç¤ºè©² DataFrame çš„è³‡è¨Šã€‚è«‹åœ¨ Colab ä¸­å®Œæˆä¸¦æä¾›åˆ†äº«é€£çµï¼Œæˆ–åœ¨ VS Code ä¸­å®Œæˆä¸¦æä¾›åŒ…å«ç¨‹å¼ç¢¼åŠçµæœçš„ HackMD é€£çµã€‚åŒæ™‚ï¼Œè«‹æä¾›èŠå¤©æ©Ÿå™¨äººçš„å°è©±ç´€éŒ„åˆ†äº«é€£çµã€‚

# è®€å…¥åŸºæœ¬å¥—ä»¶
"""

import requests
import csv
import pandas as pd

"""# å¾ TWSE çš„ç¶²ç«™ä¸‹è¼‰ CSV æ ¼å¼çš„æ¯æ—¥äº¤æ˜“è³‡æ–™"""

def download_twse_csv(date: str, type_: str = "ALL") -> str:
    """
    :param date: Date string in YYYYMMDD
    :param type_: TWSE type, default "ALL"
    :return: CSV raw text
    """
    url = f"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?date={date}&type={type_}&response=csv"
    response = requests.get(url)
    response.encoding = 'cp950'
    if response.status_code != 200:
        raise Exception(f"Failed to download: {response.status_code}")
    print("âœ… Download complete")
    return response.text

"""# å°‡åŸå§‹çš„ CSV æ–‡å­—å…§å®¹åˆ†å‰²æˆä¸€è¡Œä¸€è¡Œçš„åˆ—è¡¨"""

def extract_csv_lines(raw_text: str) -> list:
    # Clean raw text into lines, removing empty and irrelevant ones.
    lines = [line.strip() for line in raw_text.split('\n') if line.strip() and ',' in line]
    print(f"âœ… Extracted {len(lines)} non-empty lines")
    return lines

"""# åœ¨æ¸…ç†éçš„è¡Œåˆ—è¡¨ä¸­å°‹æ‰¾è³‡æ–™çš„èµ·å§‹ä½ç½®"""

def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (str, list):
    # Find header row and data rows starting from the keyword.
    header_idx = None
    for idx, line in enumerate(lines):
        if keyword in line:
            header_idx = idx
            break
    if header_idx is None:
        raise Exception("Could not find header row")
    header_line = lines[header_idx]
    data_lines = lines[header_idx + 1:]
    print(f"âœ… Found header at line {header_idx}")
    return header_line, data_lines

"""# å°‡è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œè½‰æ›æˆä¸€å€‹ä¹¾æ·¨çš„ pandas DataFrame"""

def clean_data(header_line: str, data_lines: list) -> pd.DataFrame:
    """
    Convert header and data lines to a cleaned DataFrame.
    Removes specific characters but includes all provided data lines.
    """
    header = next(csv.reader([header_line]))
    rows = list(csv.reader(data_lines))
    cleaned_rows = []
    for row in rows:
        cleaned_row = [
            cell.replace('="', '').replace('"', '').strip()
            if cell.startswith('="') else cell.replace('"', '').strip()
            for cell in row
        ]
        # Ensure the cleaned row has the same number of columns as the header
        if len(cleaned_row) == len(header):
            cleaned_rows.append(cleaned_row)
        else:
            # Skipping row due to column count mismatch
            pass #æ ¹æ“šæ¬„ä½æ•¸é‡é€²è¡Œçš„éæ¿¾ï¼Œç¢ºå¯¦å¯ä»¥å¹«åŠ©æ‚¨æ’é™¤æ‰ä¸€éƒ¨åˆ†æ ¼å¼ä¸ç¬¦çš„éæ•¸æ“šè¡Œï¼ŒåŒ…æ‹¬ä¸€äº›å‚™è¨»ã€‚
            #æˆ– print è­¦å‘Š print(f"âš ï¸ Skipping row due to column count mismatch: {row}")

    df = pd.DataFrame(cleaned_rows, columns=header)
    print(f"âœ… Created DataFrame with shape {df.shape}")
    return df

"""# Example usage"""

date = "20250702"

raw_text = download_twse_csv(date)
lines = extract_csv_lines(raw_text)
header_line, data_lines = find_data_section(lines)
df = clean_data(header_line, data_lines)

display(df.head())
display(df.tail())

from datetime import date, timedelta

start_date = date(2025, 6, 30)
end_date = date(2025, 7, 4)
delta = timedelta(days=1)
all_dates = []
current_date = start_date
while current_date <= end_date:
    all_dates.append(current_date.strftime("%Y%m%d"))
    current_date += delta
print(f"å°‡è™•ç†ä»¥ä¸‹æ—¥æœŸï¼š{all_dates}")

df_list = []
for current_date_str in all_dates:
    print(f"\næ­£åœ¨è™•ç†æ—¥æœŸï¼š{current_date_str}")
    try:
        raw_text = download_twse_csv(current_date_str)
        lines = extract_csv_lines(raw_text)
        header_line, data_lines = find_data_section(lines)
        df_day = clean_data(header_line, data_lines)
        df_day['æ—¥æœŸ'] = current_date_str # Add date column
        cols = df_day.columns.tolist() # Reorder columns to place 'æ—¥æœŸ' after 'è­‰åˆ¸åç¨±'
        cols.insert(cols.index('è­‰åˆ¸åç¨±') + 1, cols.pop(cols.index('æ—¥æœŸ')))
        df_day = df_day[cols]
        df_list.append(df_day)
    except Exception as e:
        print(f"è™•ç†æ—¥æœŸ {current_date_str} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# Concatenate all dataframes
if df_list:
    df_combined = pd.concat(df_list, ignore_index=True)
    print("\nâœ… æ‰€æœ‰æ—¥æœŸè³‡æ–™å·²åˆä½µã€‚")
else:
    df_combined = pd.DataFrame()
    print("\nâš ï¸ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ—¥æœŸè³‡æ–™ï¼Œåˆä½µçµæœç‚ºç©º DataFrameã€‚")

df_combined.info()

display(df_combined.head())
display(df_combined.tail())

"""å¹«æˆ‘è§£é‡‹ç¨‹å¼ç¢¼
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼çš„ç›®çš„æ˜¯å¾è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€ (TWSE) ä¸‹è¼‰ç‰¹å®šæ—¥æœŸçš„è‚¡ç¥¨äº¤æ˜“è³‡æ–™ï¼Œä¸¦å°‡å…¶è™•ç†æˆä¸€å€‹ pandas DataFrameã€‚

ä»¥ä¸‹æ˜¯å„å€‹éƒ¨åˆ†çš„è§£é‡‹ï¼š

download_twse_csv(date: str, type_: str = "ALL") -> str å‡½å¼ï¼š
é€™å€‹å‡½å¼è² è²¬å¾ TWSE çš„ç¶²ç«™ä¸‹è¼‰ CSV æ ¼å¼çš„æ¯æ—¥äº¤æ˜“è³‡æ–™ã€‚
date åƒæ•¸æ˜¯ä½ æƒ³è¦ä¸‹è¼‰è³‡æ–™çš„æ—¥æœŸï¼Œæ ¼å¼ç‚º YYYYMMDDã€‚
type_ åƒæ•¸æ˜¯è‚¡ç¥¨çš„é¡å‹ï¼Œé è¨­æ˜¯ "ALL" (æ‰€æœ‰è‚¡ç¥¨)ã€‚
å®ƒå»ºæ§‹ä¸€å€‹ URLï¼Œç„¶å¾Œä½¿ç”¨ requests å‡½å¼åº«ç™¼é€ GET è«‹æ±‚ã€‚
response.encoding = 'cp950' è¨­å®šç·¨ç¢¼ä»¥æ­£ç¢ºè™•ç†ä¸­æ–‡ã€‚
å¦‚æœä¸‹è¼‰å¤±æ•— (HTTP ç‹€æ…‹ç¢¼ä¸æ˜¯ 200)ï¼Œæœƒæ‹‹å‡ºä¸€å€‹ä¾‹å¤–ã€‚
æˆåŠŸä¸‹è¼‰å¾Œï¼Œæœƒå°å‡º "âœ… Download complete" ä¸¦å›å‚³åŸå§‹çš„ CSV æ–‡å­—å…§å®¹ã€‚
extract_csv_lines(raw_text: str) -> list å‡½å¼ï¼š
é€™å€‹å‡½å¼å°‡åŸå§‹çš„ CSV æ–‡å­—å…§å®¹åˆ†å‰²æˆä¸€è¡Œä¸€è¡Œçš„åˆ—è¡¨ã€‚
å®ƒæœƒç§»é™¤ç©ºç™½è¡Œå’Œä¸åŒ…å«é€—è™Ÿçš„è¡Œ (é€™äº›é€šå¸¸æ˜¯æª”æ¡ˆé–‹é ­æˆ–çµå°¾çš„èªªæ˜æ–‡å­—)ã€‚
å°å‡ºæå–åˆ°çš„éç©ºç™½è¡Œæ•¸ï¼Œä¸¦å›å‚³æ¸…ç†éçš„è¡Œåˆ—è¡¨ã€‚
find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list) å‡½å¼ï¼š
é€™å€‹å‡½å¼åœ¨æ¸…ç†éçš„è¡Œåˆ—è¡¨ä¸­å°‹æ‰¾è³‡æ–™çš„èµ·å§‹ä½ç½®ã€‚
å®ƒä»¥ "è­‰åˆ¸ä»£è™Ÿ" ä½œç‚ºé—œéµå­—ä¾†å°‹æ‰¾è¡¨é ­ (header)ã€‚
æ‰¾åˆ°è¡¨é ­å¾Œï¼Œæœƒå°‡è¡¨é ­è¡Œå’Œå…¶å¾Œçš„æ‰€æœ‰è¡Œ (è³‡æ–™è¡Œ) åˆ†é–‹ã€‚
å¦‚æœæ‰¾ä¸åˆ°è¡¨é ­ï¼Œæœƒæ‹‹å‡ºä¸€å€‹ä¾‹å¤–ã€‚
å°å‡ºæ‰¾åˆ°è¡¨é ­çš„è¡Œæ•¸ï¼Œä¸¦å›å‚³è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œçš„åˆ—è¡¨ã€‚
clean_data(header_line: str, data_lines: list) -> pd.DataFrame å‡½å¼ï¼š
é€™å€‹å‡½å¼è² è²¬å°‡è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œè½‰æ›æˆä¸€å€‹ä¹¾æ·¨çš„ pandas DataFrameã€‚
å®ƒä½¿ç”¨ csv.reader ä¾†æ­£ç¢ºè§£æ CSV æ ¼å¼çš„è¡Œã€‚
åœ¨è™•ç†è³‡æ–™è¡Œæ™‚ï¼Œå®ƒæœƒç§»é™¤å„²å­˜æ ¼é–‹é ­çš„ =" å’Œçµå°¾çš„ "ï¼Œä¸¦å»é™¤å‰å¾Œçš„ç©ºç™½å­—å…ƒï¼Œä»¥ç¢ºä¿è³‡æ–™æ˜¯ä¹¾æ·¨çš„ã€‚
æœ€å¾Œï¼Œä½¿ç”¨æ¸…ç†éçš„è³‡æ–™å»ºç«‹ä¸€å€‹ pandas DataFrameã€‚
å°å‡ºå»ºç«‹å¥½çš„ DataFrame çš„å½¢ç‹€ (åˆ—æ•¸å’Œæ¬„æ•¸)ï¼Œä¸¦å›å‚³ DataFrameã€‚
ç¯„ä¾‹ä½¿ç”¨éƒ¨åˆ† (# ğŸ¯ Example usage)ï¼š
è¨­å®šäº†ä¸€å€‹ç¯„ä¾‹æ—¥æœŸ date = "20250702"ã€‚
ä¾åºå‘¼å«ä¸Šé¢å®šç¾©çš„å››å€‹å‡½å¼ï¼šä¸‹è¼‰åŸå§‹æ–‡å­—ã€æå–è¡Œã€å°‹æ‰¾è³‡æ–™å€æ®µã€æ¸…ç†è³‡æ–™ä¸¦å»ºç«‹ DataFrameã€‚
æœ€å¾Œä½¿ç”¨ df.head() é¡¯ç¤º DataFrame çš„å‰å¹¾è¡Œã€‚
ç¸½çµä¾†èªªï¼Œé€™æ®µç¨‹å¼ç¢¼æä¾›äº†ä¸€å€‹è‡ªå‹•åŒ–ä¸‹è¼‰å’Œåˆæ­¥è™•ç† TWSE æ¯æ—¥äº¤æ˜“è³‡æ–™çš„æµç¨‹ã€‚


è«‹ä½¿ç”¨pythonå»å®Œæˆ åˆä½µ6/30ï½7/4çš„è‚¡ç¥¨è³‡æ–™ æ¯æ—¥æ”¶ç›¤è¡Œæƒ…(å…¨éƒ¨) æˆç‚ºä¸€å¼µè³‡æ–™è¡¨ (Data Frame) ä½¿ç”¨ Colab ä¸Šå‚³ colab åˆ†äº«é€£çµ ä½¿ç”¨vs code ç¹³äº¤ HackMD é€£çµï¼Œè¦åŒ…å«ç¨‹å¼ç¢¼åŠçµæœ è«‹ä¸Šå‚³ èŠå¤©æ©Ÿå™¨äººçš„å°è©±ç´€éŒ„åˆ†äº«é€£çµ è«‹ä½¿ç”¨df.info() çµ¦æ•´ç†å®Œæˆ df è³‡è¨Š
å¥½çš„ï¼Œé€™æ˜¯ä¸€å€‹å¤šæ­¥é©Ÿçš„ä»»å‹™ã€‚æˆ‘å°‡ç‚ºæ‚¨åˆ¶å®šä¸€å€‹è¨ˆç•«ä¾†å®Œæˆé€™å€‹ä»»å‹™ï¼ŒåŒ…æ‹¬ä¸‹è¼‰å¤šå¤©çš„è³‡æ–™ã€åˆä½µã€ä»¥åŠé¡¯ç¤º DataFrame çš„è³‡è¨Šã€‚

ä»¥ä¸‹æ˜¯è¨ˆç•«æ­¥é©Ÿï¼š

ä¸‹è¼‰å¤šæ—¥è³‡æ–™: è¿­ä»£æŒ‡å®šæ—¥æœŸç¯„åœï¼Œä½¿ç”¨å·²å®šç¾©çš„ download_twse_csvã€extract_csv_linesã€find_data_section å’Œ clean_data å‡½å¼ä¸‹è¼‰ä¸¦è™•ç†æ¯ä¸€å¤©çš„è³‡æ–™ã€‚
åˆä½µè³‡æ–™: å°‡å¤šå¤©çš„ DataFrame åˆä½µæˆä¸€å€‹å–®ä¸€çš„ DataFrameã€‚
æ–°å¢æ—¥æœŸæ¬„ä½: åœ¨åˆä½µå¾Œçš„ DataFrame ä¸­æ–°å¢ä¸€å€‹æ¬„ä½ï¼Œæ¨™ç¤ºæ¯ç­†è³‡æ–™çš„æ—¥æœŸã€‚
é¡¯ç¤º DataFrame è³‡è¨Š: ä½¿ç”¨ df.info() é¡¯ç¤ºåˆä½µå¾Œ DataFrame çš„è³‡è¨Šã€‚
Finish task: æ•´ç†ç¨‹å¼ç¢¼å’Œçµæœï¼Œæº–å‚™åˆ†äº«ã€‚
ä¸‹è¼‰å¤šæ—¥è³‡æ–™: è¿­ä»£æŒ‡å®šæ—¥æœŸç¯„åœ (20240630 ~ 20240704)ï¼Œä½¿ç”¨å·²å®šç¾©çš„å‡½å¼ä¸‹è¼‰ä¸¦è™•ç†æ¯ä¸€å¤©çš„ TWSE è‚¡ç¥¨è³‡æ–™ã€‚
åˆä½µè³‡æ–™: å°‡ä¸‹è¼‰çš„æ¯æ—¥ DataFrame å„²å­˜åˆ°ä¸€å€‹åˆ—è¡¨ä¸­ï¼Œç„¶å¾Œä½¿ç”¨ pandas çš„ concat å‡½å¼å°‡å®ƒå€‘åˆä½µæˆä¸€å€‹å–®ä¸€çš„ DataFrameã€‚
æ–°å¢æ—¥æœŸæ¬„ä½: åœ¨åˆä½µå¾Œçš„ DataFrame ä¸­æ–°å¢ä¸€å€‹åç‚º 'æ—¥æœŸ' çš„æ¬„ä½ï¼Œç”¨ä¾†è¨˜éŒ„æ¯ç­†è³‡æ–™çš„åŸå§‹æ—¥æœŸã€‚
é¡¯ç¤º dataframe è³‡è¨Š: ä½¿ç”¨ df.info() æ–¹æ³•é¡¯ç¤ºåˆä½µå¾Œ DataFrame çš„æ¬„ä½è³‡è¨Šã€è³‡æ–™é¡å‹å’Œè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ã€‚
Finish task: æ•´ç†ä¸¦æä¾›å®Œæˆå¾Œçš„ç¨‹å¼ç¢¼å’Œçµæœçš„åˆ†äº«é€£çµã€‚
ç”Ÿæˆä¸­...
Preparing
ä¸‹è¼‰å¤šæ—¥è³‡æ–™
åˆä½µè³‡æ–™
æ–°å¢æ—¥æœŸæ¬„ä½
é¡¯ç¤º dataframe è³‡è¨Š
Finish task

è«‹èªªæ˜é€™æ®µç¨‹å¼ç¢¼ï¼š

é€™è¡Œç¨‹å¼ç¢¼çš„ä½œç”¨æ˜¯å°‡åŸå§‹ä¸‹è¼‰çš„ CSV æ–‡å­— (raw_text) è™•ç†æˆä¸€å€‹ä¹¾æ·¨çš„è¡Œåˆ—è¡¨ (lines)ã€‚

è©³ç´°è§£é‡‹å¦‚ä¸‹ï¼š

raw_text.split('\n'): é€™éƒ¨åˆ†æœƒå°‡åŸå§‹æ–‡å­—æŒ‰ç…§æ›è¡Œç¬¦è™Ÿ (\n) åˆ†å‰²æˆä¸€å€‹åˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­çš„æ¯å€‹å…ƒç´ ä»£è¡¨åŸå§‹æ–‡å­—ä¸­çš„ä¸€è¡Œã€‚
[... for line in ...]: é€™æ˜¯ä¸€å€‹åˆ—è¡¨æ¨å°å¼ (list comprehension)ï¼Œå®ƒæœƒéæ­· raw_text.split('\n') ç”Ÿæˆçš„æ¯ä¸€è¡Œã€‚
line.strip(): å°æ¯ä¸€è¡Œä½¿ç”¨ .strip() æ–¹æ³•ï¼Œé€™æœƒç§»é™¤è©²è¡Œé–‹é ­å’Œçµå°¾çš„ç©ºç™½å­—å…ƒ (åŒ…æ‹¬ç©ºæ ¼ã€æ›è¡Œç¬¦ã€è£½è¡¨ç¬¦ç­‰)ã€‚
if line.strip() and ',' in line: é€™æ˜¯ä¸€å€‹éæ¿¾æ¢ä»¶ï¼Œåªæœ‰æ»¿è¶³é€™å€‹æ¢ä»¶çš„è¡Œæ‰æœƒè¢«åŒ…å«åœ¨æœ€çµ‚çš„ lines åˆ—è¡¨ä¸­ã€‚
line.strip(): æª¢æŸ¥å»é™¤ç©ºç™½å­—å…ƒå¾Œçš„è¡Œæ˜¯å¦ç‚ºéç©ºå­—ä¸²ã€‚é€™å¯ä»¥æ’é™¤åŸå§‹æ–‡å­—ä¸­çš„ç©ºç™½è¡Œã€‚
',' in line: æª¢æŸ¥å»é™¤ç©ºç™½å­—å…ƒå¾Œçš„è¡Œæ˜¯å¦åŒ…å«é€—è™Ÿã€‚TWSE ä¸‹è¼‰çš„ CSV æª”æ¡ˆåœ¨è³‡æ–™é–‹å§‹ä¹‹å‰æœƒæœ‰å¹¾è¡Œèªªæ˜æ–‡å­—ï¼Œé€™äº›æ–‡å­—é€šå¸¸ä¸åŒ…å«é€—è™Ÿï¼Œé€šéé€™å€‹æ¢ä»¶å¯ä»¥éæ¿¾æ‰é€™äº›éè³‡æ–™è¡Œã€‚
ç¸½ä¹‹ï¼Œé€™è¡Œç¨‹å¼ç¢¼æœ‰æ•ˆåœ°æ¸…é™¤äº†åŸå§‹ CSV æ–‡å­—ä¸­çš„ç©ºç™½è¡Œå’Œé–‹é ­çš„èªªæ˜æ–‡å­—ï¼Œåªä¿ç•™äº†çœ‹ä¼¼æ˜¯å¯¦éš›è³‡æ–™çš„è¡Œã€‚


def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list): æˆ‘æƒ³è¦çŸ¥é“é€™æ®µå‡½å¼ç¨‹å¼ç¢¼çš„åˆ†è§£æ„ç¾©
å¥½çš„ï¼Œé€™å€‹ find_data_section å‡½å¼çš„ç›®çš„æ˜¯åœ¨å¾ TWSE ä¸‹è¼‰ä¸¦åˆæ­¥è™•ç†éçš„è¡Œåˆ—è¡¨ (lines) ä¸­ï¼Œæ‰¾åˆ°å¯¦éš›çš„è³‡æ–™éƒ¨åˆ†ï¼Œä¸¦å°‡è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œåˆ†é–‹ã€‚

ä»¥ä¸‹æ˜¯é€™æ®µå‡½å¼çš„è©³ç´°åˆ†è§£èªªæ˜ï¼š

def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list)::
å®šç¾©äº†ä¸€å€‹åç‚º find_data_section çš„å‡½å¼ã€‚
å®ƒæ¥å—å…©å€‹åƒæ•¸ï¼š
lines: list: é€™æ˜¯è¼¸å…¥çš„åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹åŒ…å«å­—ä¸²çš„åˆ—è¡¨ï¼Œæ¯ä¸€å­—ä¸²ä»£è¡¨ CSV æª”æ¡ˆä¸­çš„ä¸€è¡Œã€‚
keyword: str = "è­‰åˆ¸ä»£è™Ÿ": é€™æ˜¯å¦ä¸€å€‹è¼¸å…¥åƒæ•¸ï¼ŒæŒ‡å®šç”¨ä¾†å°‹æ‰¾è³‡æ–™å€æ®µèµ·å§‹çš„é—œéµå­—ã€‚é è¨­å€¼æ˜¯ "è­‰åˆ¸ä»£è™Ÿ"ï¼Œå› ç‚ºåœ¨ TWSE çš„ CSV æª”æ¡ˆä¸­ï¼Œè³‡æ–™çš„è¡¨é ­é€šå¸¸ä»¥é€™å€‹è©é–‹å§‹ã€‚
-> (list, list): é€™æ˜¯å‡½å¼çš„å‹åˆ¥æç¤º (type hint)ï¼Œè¡¨ç¤ºé€™å€‹å‡½å¼é æœŸæœƒå›å‚³ä¸€å€‹åŒ…å«å…©å€‹åˆ—è¡¨çš„å…ƒçµ„ (tuple)ï¼Œç¬¬ä¸€å€‹åˆ—è¡¨æ˜¯è¡¨é ­è¡Œï¼Œç¬¬äºŒå€‹åˆ—è¡¨æ˜¯è³‡æ–™è¡Œã€‚
header_idx = None:
åˆå§‹åŒ–ä¸€å€‹è®Šæ•¸ header_idx ç‚º Noneã€‚é€™å€‹è®Šæ•¸å°‡ç”¨ä¾†å„²å­˜æ‰¾åˆ°è¡¨é ­è¡Œçš„ç´¢å¼•ä½ç½®ã€‚
for idx, line in enumerate(lines)::
é€™æ˜¯ä¸€å€‹ for è¿´åœˆï¼Œç”¨æ–¼éæ­·è¼¸å…¥çš„ lines åˆ—è¡¨ã€‚
enumerate(lines) æœƒåŒæ™‚æä¾›æ¯å€‹å…ƒç´ çš„ç´¢å¼• (idx) å’Œå…ƒç´ æœ¬èº« (line)ã€‚
if keyword in line::
åœ¨è¿´åœˆçš„æ¯æ¬¡è¿­ä»£ä¸­ï¼Œæª¢æŸ¥ç•¶å‰è¡Œ (line) æ˜¯å¦åŒ…å«æŒ‡å®šçš„ keyword (é è¨­æ˜¯ "è­‰åˆ¸ä»£è™Ÿ")ã€‚
header_idx = idx:
å¦‚æœç•¶å‰è¡ŒåŒ…å«é—œéµå­—ï¼Œå‰‡å°‡ç•¶å‰è¡Œçš„ç´¢å¼• (idx) è³¦å€¼çµ¦ header_idxã€‚é€™è¡¨ç¤ºæˆ‘å€‘æ‰¾åˆ°äº†è¡¨é ­è¡Œçš„ä½ç½®ã€‚
break:
ä¸€æ—¦æ‰¾åˆ°è¡¨é ­è¡Œï¼Œå°±ä½¿ç”¨ break èªå¥ç«‹å³é€€å‡ºè¿´åœˆï¼Œå› ç‚ºæˆ‘å€‘åªéœ€è¦æ‰¾åˆ°ç¬¬ä¸€å€‹åŒ…å«é—œéµå­—çš„è¡Œä½œç‚ºè¡¨é ­ã€‚
if header_idx is None::
åœ¨è¿´åœˆçµæŸå¾Œï¼Œæª¢æŸ¥ header_idx æ˜¯å¦ä»ç„¶æ˜¯ Noneã€‚
å¦‚æœ header_idx æ˜¯ Noneï¼Œè¡¨ç¤ºåœ¨æ•´å€‹ lines åˆ—è¡¨ä¸­éƒ½æ²’æœ‰æ‰¾åˆ°åŒ…å«æŒ‡å®šé—œéµå­—çš„è¡Œã€‚
raise Exception("Could not find header row"):
å¦‚æœåœ¨ä¸Šä¸€æ­¥æª¢æŸ¥ä¸­ç™¼ç¾æ²’æœ‰æ‰¾åˆ°è¡¨é ­è¡Œï¼Œå‰‡æ‹‹å‡ºä¸€å€‹ Exceptionï¼Œä¸¦é™„å¸¶éŒ¯èª¤è¨Šæ¯ "Could not find header row"ï¼Œå‘Šè¨´ä½¿ç”¨è€…ç„¡æ³•å®šä½è³‡æ–™å€æ®µã€‚
header_line = lines[header_idx]:
å¦‚æœæ‰¾åˆ°äº†è¡¨é ­è¡Œ (å³ header_idx ä¸æ˜¯ None)ï¼Œå°±ä½¿ç”¨ header_idx å¾ lines åˆ—è¡¨ä¸­å–å‡ºè¡¨é ­è¡Œï¼Œä¸¦è³¦å€¼çµ¦ header_line è®Šæ•¸ã€‚
data_lines = lines[header_idx + 1:]:
ä½¿ç”¨åˆ‡ç‰‡ (slicing) çš„æ–¹å¼ï¼Œå¾ lines åˆ—è¡¨ä¸­å–å‡ºè¡¨é ­è¡Œä¹‹å¾Œçš„æ‰€æœ‰è¡Œã€‚header_idx + 1 è¡¨ç¤ºå¾è¡¨é ­è¡Œçš„ä¸‹ä¸€è¡Œé–‹å§‹ï¼Œ: è¡¨ç¤ºç›´åˆ°åˆ—è¡¨çš„æœ«å°¾ã€‚é€™äº›è¡Œè¢«è³¦å€¼çµ¦ data_lines è®Šæ•¸ã€‚
print(f"âœ… Found header at line {header_idx}"):
å°å‡ºä¸€æ¢æˆåŠŸè¨Šæ¯ï¼Œè¡¨æ˜æ‰¾åˆ°äº†è¡¨é ­è¡Œï¼Œä¸¦é¡¯ç¤ºå…¶ç´¢å¼•ä½ç½®ã€‚
return header_line, data_lines:
æœ€å¾Œï¼Œå‡½å¼å›å‚³ä¸€å€‹å…ƒçµ„ï¼Œå…¶ä¸­åŒ…å« header_line (å–®ä¸€å€‹å­—ä¸²) å’Œ data_lines (ä¸€å€‹å­—ä¸²åˆ—è¡¨)ã€‚
ç¸½ä¹‹ï¼Œé€™å€‹å‡½å¼çš„æ ¸å¿ƒåŠŸèƒ½å°±æ˜¯é€šéå°‹æ‰¾ä¸€å€‹ç‰¹å®šçš„é—œéµå­—ä¾†è‡ªå‹•å®šä½ CSV è³‡æ–™çš„èµ·å§‹é»ï¼Œä¸¦å°‡è¡¨é ­å’Œå¯¦éš›çš„è³‡æ–™è¨˜éŒ„åˆ†é–‹ï¼Œç‚ºå¾ŒçºŒçš„è³‡æ–™è™•ç†åšæº–å‚™ã€‚


è«‹èªªæ˜é€™æ®µç¨‹å¼ç¢¼ï¼š

å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼å®šç¾©äº†å¹¾å€‹å‡½å¼ï¼Œç”¨æ–¼å¾è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€ (TWSE) ä¸‹è¼‰æ¯æ—¥æ”¶ç›¤è¡Œæƒ…æ•¸æ“šï¼Œä¸¦å°‡å…¶è™•ç†æˆä¸€å€‹ pandas DataFrameã€‚

ä»¥ä¸‹æ˜¯å„å€‹éƒ¨åˆ†çš„è©³ç´°è§£é‡‹ï¼š

Import å‡½å¼åº«:
import requests: å°å…¥ requests å‡½å¼åº«ï¼Œç”¨æ–¼ç™¼é€ HTTP è«‹æ±‚ä¾†ä¸‹è¼‰ç¶²é å…§å®¹ã€‚
import csv: å°å…¥ csv å‡½å¼åº«ï¼Œç”¨æ–¼è§£æ CSV æ ¼å¼çš„æ•¸æ“šã€‚
import pandas as pd: å°å…¥ pandas å‡½å¼åº«ï¼Œä¸¦å°‡å…¶åˆ¥åç‚º pdï¼Œç”¨æ–¼æ•¸æ“šè™•ç†å’Œåˆ†æï¼Œç‰¹åˆ¥æ˜¯ DataFrame çš„æ“ä½œã€‚
download_twse_csv(date: str, type_: str = "ALL") -> str å‡½å¼:
åŠŸèƒ½: ä¸‹è¼‰æŒ‡å®šæ—¥æœŸå’Œé¡å‹çš„ TWSE æ¯æ—¥ CSV æ•¸æ“šã€‚
åƒæ•¸:
date: å­—ä¸²ï¼Œæ ¼å¼ç‚º YYYYMMDDï¼Œè¡¨ç¤ºè¦ä¸‹è¼‰æ•¸æ“šçš„æ—¥æœŸã€‚
type_: å­—ä¸²ï¼Œè¡¨ç¤ºè‚¡ç¥¨é¡å‹ï¼Œé è¨­ç‚º "ALL" (å…¨éƒ¨)ã€‚
å›å‚³å€¼: å­—ä¸²ï¼ŒåŸå§‹çš„ CSV æ–‡æœ¬å…§å®¹ã€‚
å…§éƒ¨å·¥ä½œ:
æ§‹å»º TWSE æ•¸æ“šä¸‹è¼‰çš„ URLã€‚
ä½¿ç”¨ requests.get() ç™¼é€ GET è«‹æ±‚ä¸‹è¼‰æ•¸æ“šã€‚
è¨­å®šéŸ¿æ‡‰ç·¨ç¢¼ç‚º cp950ï¼Œä»¥æ­£ç¢ºè™•ç†ä¸­æ–‡ã€‚
æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼ï¼Œå¦‚æœä¸æ˜¯ 200 (æˆåŠŸ)ï¼Œå‰‡æ‹‹å‡ºä¾‹å¤–ã€‚
æˆåŠŸä¸‹è¼‰å¾Œï¼Œå°å‡ºå®Œæˆè¨Šæ¯ä¸¦å›å‚³æ•¸æ“šæ–‡æœ¬ã€‚
extract_csv_lines(raw_text: str) -> list å‡½å¼:
åŠŸèƒ½: æ¸…ç†åŸå§‹ CSV æ–‡æœ¬ï¼Œæå–æœ‰æ•ˆçš„æ•¸æ“šè¡Œã€‚
åƒæ•¸: raw_text: å­—ä¸²ï¼Œdownload_twse_csv ä¸‹è¼‰çš„åŸå§‹ CSV æ–‡æœ¬ã€‚
å›å‚³å€¼: åˆ—è¡¨ï¼ŒåŒ…å«æ¸…ç†å¾Œçš„æ•¸æ“šè¡Œå­—ä¸²ã€‚
å…§éƒ¨å·¥ä½œ:
å°‡åŸå§‹æ–‡æœ¬æŒ‰æ›è¡Œç¬¦åˆ†å‰²æˆè¡Œã€‚
ä½¿ç”¨åˆ—è¡¨æ¨å°å¼éæ¿¾æ‰ç©ºç™½è¡Œå’Œä¸åŒ…å«é€—è™Ÿçš„è¡Œ (é€šå¸¸æ˜¯æª”æ¡ˆé–‹é ­çš„èªªæ˜æ–‡å­—)ã€‚
å°å‡ºæå–åˆ°çš„éç©ºç™½è¡Œæ•¸ã€‚
find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list) å‡½å¼:
åŠŸèƒ½: åœ¨æ•¸æ“šè¡Œåˆ—è¡¨ä¸­æ‰¾åˆ°å¯¦éš›æ•¸æ“šé–‹å§‹çš„ä½ç½® (è¡¨é ­è¡Œ)ã€‚
åƒæ•¸:
lines: åˆ—è¡¨ï¼Œextract_csv_lines æå–çš„æ•¸æ“šè¡Œåˆ—è¡¨ã€‚
keyword: å­—ä¸²ï¼Œç”¨æ–¼å°‹æ‰¾è¡¨é ­çš„é—œéµå­—ï¼Œé è¨­ç‚º "è­‰åˆ¸ä»£è™Ÿ"ã€‚
å›å‚³å€¼: å…ƒçµ„ï¼ŒåŒ…å«è¡¨é ­è¡Œå­—ä¸²å’Œè³‡æ–™è¡Œåˆ—è¡¨ã€‚
å…§éƒ¨å·¥ä½œ:
éæ­·æ•¸æ“šè¡Œï¼Œå°‹æ‰¾åŒ…å«æŒ‡å®šé—œéµå­—çš„è¡Œã€‚
æ‰¾åˆ°å¾Œï¼Œå°‡è©²è¡Œè¦–ç‚ºè¡¨é ­è¡Œï¼Œå…¶å¾Œçš„è¡Œè¦–ç‚ºè³‡æ–™è¡Œã€‚
å¦‚æœæ‰¾ä¸åˆ°è¡¨é ­è¡Œï¼Œå‰‡æ‹‹å‡ºä¾‹å¤–ã€‚
å°å‡ºæ‰¾åˆ°è¡¨é ­è¡Œçš„ç´¢å¼•ä½ç½®ã€‚
clean_data(header_line: str, data_lines: list) -> pd.DataFrame å‡½å¼:
åŠŸèƒ½: å°‡è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œè½‰æ›ç‚ºä¹¾æ·¨çš„ pandas DataFrameã€‚
åƒæ•¸:
header_line: å­—ä¸²ï¼Œè¡¨é ­è¡Œã€‚
data_lines: åˆ—è¡¨ï¼Œè³‡æ–™è¡Œã€‚
å›å‚³å€¼: pandas DataFrameï¼ŒåŒ…å«æ¸…ç†å¾Œçš„æ•¸æ“šã€‚
å…§éƒ¨å·¥ä½œ:
ä½¿ç”¨ csv.reader è§£æè¡¨é ­è¡Œå’Œè³‡æ–™è¡Œã€‚
éæ­·è³‡æ–™è¡Œï¼Œå°æ¯å€‹å–®å…ƒæ ¼é€²è¡Œæ¸…ç†ï¼Œç§»é™¤ =", " ç­‰å¯èƒ½å½±éŸ¿æ•¸æ“šé¡å‹çš„å­—å…ƒä¸¦å»é™¤å‰å¾Œç©ºç™½ã€‚
ä½¿ç”¨æ¸…ç†å¾Œçš„æ•¸æ“šå’Œè¡¨é ­å‰µå»ºä¸€å€‹ pandas DataFrameã€‚
å°å‡ºå‰µå»ºå¥½çš„ DataFrame çš„å½¢ç‹€ã€‚
ç¯„ä¾‹ä½¿ç”¨éƒ¨åˆ†:
è¨­å®šäº†ä¸€å€‹ç¯„ä¾‹æ—¥æœŸ date = "20250702"ã€‚
ä¾åºå‘¼å«ä¸Šè¿°å››å€‹å‡½å¼ï¼Œä¸‹è¼‰ã€æå–ã€å°‹æ‰¾æ•¸æ“šå€æ®µä¸¦æ¸…ç†æ•¸æ“šï¼Œæœ€çµ‚ç”Ÿæˆä¸€å€‹ pandas DataFrame å„²å­˜åˆ° df è®Šæ•¸ä¸­ã€‚
æœ€å¾Œä½¿ç”¨ df.head() é¡¯ç¤º DataFrame çš„å‰äº”è¡Œï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥çœ‹æ•¸æ“šå…§å®¹ã€‚
ç¸½çš„ä¾†èªªï¼Œé€™æ®µç¨‹å¼ç¢¼æä¾›äº†ä¸€å¥—å®Œæ•´çš„æµç¨‹ï¼Œç”¨æ–¼è‡ªå‹•åŒ–å¾ TWSE ç¶²ç«™ç²å–ã€æ¸…ç†å’Œåˆæ­¥è™•ç†æ¯æ—¥è‚¡ç¥¨äº¤æ˜“æ•¸æ“šã€‚


import requests import csv import pandas as pd def download_twse_csv(date: str, type_: str = "ALL") -> str: ''' Download TWSE daily CSV data as text. :param date: Date string in YYYYMMDD :param type_: TWSE type, default "ALL" :return: CSV raw text ''' url = f"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?date={date}&type={type_}&response=csv" response = requests.get(url) response.encoding = 'cp950' if response.status_code != 200: raise Exception(f"Failed to download: {response.status_code}") print("âœ… Download complete") return response.text å¹«æˆ‘é€è¡Œè§£é‡‹
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼å®šç¾©äº†ä¸€å€‹åç‚º download_twse_csv çš„å‡½å¼ï¼Œç”¨æ–¼å¾è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€ (TWSE) çš„ç¶²ç«™ä¸‹è¼‰ç‰¹å®šæ—¥æœŸçš„æ¯æ—¥æ”¶ç›¤è¡Œæƒ… CSV æ•¸æ“šã€‚

ä»¥ä¸‹æ˜¯é€è¡Œè§£é‡‹ï¼š

import requests: é€™ä¸€è¡Œå°å…¥äº† Python çš„ requests å‡½å¼åº«ï¼Œé€™å€‹å‡½å¼åº«æ˜¯ç”¨ä¾†æ–¹ä¾¿åœ°ç™¼é€ HTTP è«‹æ±‚çš„ï¼Œä¾‹å¦‚å¾ç¶²è·¯ä¸Šç²å–æ•¸æ“šã€‚
import csv: é€™ä¸€è¡Œå°å…¥äº† Python çš„ csv æ¨¡çµ„ï¼Œé€™å€‹æ¨¡çµ„æä¾›äº†è®€å–å’Œå¯«å…¥ CSV (Comma Separated Values) æ ¼å¼æª”æ¡ˆçš„åŠŸèƒ½ã€‚é›–ç„¶åœ¨é€™å€‹ç‰¹å®šçš„å‡½å¼ä¸­æ²’æœ‰ç›´æ¥ç”¨åˆ° csv æ¨¡çµ„çš„åŠŸèƒ½ï¼Œä½†åœ¨æ•´å€‹ç­†è¨˜æœ¬çš„å…¶ä»–éƒ¨åˆ†å¯èƒ½æœƒç”¨åˆ°ï¼Œä¾‹å¦‚è§£æä¸‹è¼‰ä¸‹ä¾†çš„ CSV æ•¸æ“šã€‚
import pandas as pd: é€™ä¸€è¡Œå°å…¥äº† pandas å‡½å¼åº«ï¼Œä¸¦å°‡å…¶åˆ¥åç‚º pdã€‚pandas æ˜¯ä¸€å€‹å¼·å¤§çš„æ•¸æ“šè™•ç†å’Œåˆ†æå·¥å…·ï¼Œç‰¹åˆ¥æ˜¯å®ƒæä¾›äº† DataFrame é€™å€‹æ•¸æ“šçµæ§‹ï¼Œéå¸¸é©åˆè™•ç†è¡¨æ ¼å‹çš„æ•¸æ“šã€‚åŒæ¨£åœ°ï¼Œé›–ç„¶åœ¨é€™å€‹å‡½å¼æœ¬èº«æ²’æœ‰ç”¨åˆ° pandasï¼Œä½†åœ¨å¾ŒçºŒè™•ç†ä¸‹è¼‰æ•¸æ“šæ™‚æœƒç”¨åˆ°ã€‚
def download_twse_csv(date: str, type_: str = "ALL") -> str:: é€™ä¸€è¡Œå®šç¾©äº†ä¸€å€‹å‡½å¼ï¼Œåç‚º download_twse_csvã€‚
date: str: æŒ‡å®šå‡½å¼æ¥å—ä¸€å€‹åç‚º date çš„åƒæ•¸ï¼Œä¸¦ä¸”é æœŸé€™å€‹åƒæ•¸æ˜¯ä¸€å€‹å­—ä¸² (string)ã€‚
type_: str = "ALL": æŒ‡å®šå‡½å¼æ¥å—ä¸€å€‹åç‚º type_ çš„åƒæ•¸ï¼Œé æœŸé€™å€‹åƒæ•¸æ˜¯ä¸€å€‹å­—ä¸²ï¼Œä¸¦ä¸”å¦‚æœå‘¼å«å‡½å¼æ™‚æ²’æœ‰æä¾› type_ åƒæ•¸ï¼Œå®ƒçš„é è¨­å€¼æ˜¯ "ALL"ã€‚
-> str: é€™æ˜¯å‡½å¼çš„å‹åˆ¥æç¤º (type hint)ï¼Œè¡¨ç¤ºé€™å€‹å‡½å¼é æœŸæœƒå›å‚³ä¸€å€‹å­—ä¸²ã€‚
''' ... ''': é€™æ˜¯ä¸€å€‹å¤šè¡Œå­—ä¸²ï¼Œç”¨ä½œå‡½å¼çš„èªªæ˜æ–‡ä»¶ (docstring)ã€‚å®ƒè§£é‡‹äº†å‡½å¼çš„åŠŸèƒ½ã€åƒæ•¸å’Œå›å‚³å€¼ã€‚
Download TWSE daily CSV data as text.: èªªæ˜å‡½å¼çš„åŠŸèƒ½æ˜¯ä¸‹è¼‰ TWSE æ¯æ—¥ CSV æ•¸æ“šçš„æ–‡æœ¬å…§å®¹ã€‚
:param date: Date string in YYYYMMDD: èªªæ˜ date åƒæ•¸çš„ç”¨é€”å’Œæ ¼å¼ã€‚
:param type_: TWSE type, default "ALL": èªªæ˜ type_ åƒæ•¸çš„ç”¨é€”å’Œé è¨­å€¼ã€‚
:return: CSV raw text: èªªæ˜å‡½å¼çš„å›å‚³å€¼æ˜¯ä»€éº¼ã€‚
url = f"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?date={date}&type={type_}&response=csv": é€™ä¸€è¡Œæ§‹å»ºäº†è¦ä¸‹è¼‰æ•¸æ“šçš„ç¶²å€ (URL)ã€‚å®ƒä½¿ç”¨äº† F-string (æ ¼å¼åŒ–å­—ä¸²å­—é¢å€¼)ï¼Œå°‡ date å’Œ type_ åƒæ•¸çš„å€¼åµŒå…¥åˆ°ç¶²å€ä¸­ã€‚é€™æ˜¯ TWSE æä¾›æ•¸æ“šä¸‹è¼‰çš„ç‰¹å®šç¶²å€æ ¼å¼ã€‚
response = requests.get(url): é€™ä¸€è¡Œä½¿ç”¨ requests.get() å‡½å¼å‘ä¸Šé¢æ§‹å»ºçš„ URL ç™¼é€ä¸€å€‹ HTTP GET è«‹æ±‚ã€‚è«‹æ±‚çš„çµæœ (åŒ…æ‹¬ç‹€æ…‹ç¢¼ã€å›å‚³çš„æ•¸æ“šç­‰) è¢«å„²å­˜åœ¨ response è®Šæ•¸ä¸­ã€‚
response.encoding = 'cp950': é€™ä¸€è¡Œè¨­å®šäº† response çš„ç·¨ç¢¼ç‚º cp950ã€‚é€™æ˜¯å› ç‚º TWSE çš„ç¶²ç«™å¯èƒ½ä½¿ç”¨é€™ç¨®ç·¨ç¢¼ä¾†é¡¯ç¤ºä¸­æ–‡ï¼Œè¨­å®šæ­£ç¢ºçš„ç·¨ç¢¼å¯ä»¥ç¢ºä¿å›å‚³çš„æ–‡æœ¬å…§å®¹èƒ½å¤ è¢«æ­£ç¢ºåœ°è§£ç¢¼ï¼Œé¿å…äº‚ç¢¼ã€‚
if response.status_code != 200:: é€™ä¸€è¡Œæª¢æŸ¥ HTTP è«‹æ±‚çš„ç‹€æ…‹ç¢¼ (response.status_code) æ˜¯å¦ä¸ç­‰æ–¼ 200ã€‚ç‹€æ…‹ç¢¼ 200 è¡¨ç¤ºè«‹æ±‚æˆåŠŸã€‚å¦‚æœç‹€æ…‹ç¢¼ä¸æ˜¯ 200ï¼Œè¡¨ç¤ºä¸‹è¼‰éç¨‹ä¸­ç™¼ç”Ÿäº†å•é¡Œ (ä¾‹å¦‚é é¢ä¸å­˜åœ¨ã€ä¼ºæœå™¨éŒ¯èª¤ç­‰)ã€‚
raise Exception(f"Failed to download: {response.status_code}"): å¦‚æœç‹€æ…‹ç¢¼ä¸ç­‰æ–¼ 200ï¼Œé€™ä¸€è¡Œå°±æœƒæ‹‹å‡ºä¸€å€‹ Exception (ä¾‹å¤–æˆ–éŒ¯èª¤)ã€‚ä¾‹å¤–è¨Šæ¯æœƒåŒ…å«å¤±æ•—çš„åŸå› å’Œ HTTP ç‹€æ…‹ç¢¼ã€‚é€™æœƒä¸­æ–·ç¨‹å¼çš„åŸ·è¡Œä¸¦æç¤ºéŒ¯èª¤ã€‚
print("âœ… Download complete"): å¦‚æœç‹€æ…‹ç¢¼æ˜¯ 200 (ä¸‹è¼‰æˆåŠŸ)ï¼Œé€™ä¸€è¡ŒæœƒåŸ·è¡Œï¼Œä¸¦å°å‡ºä¸€å€‹å¸¶æœ‰å‹¾è™Ÿçš„è¨Šæ¯ "âœ… Download complete"ï¼Œè¡¨ç¤ºä¸‹è¼‰å·²å®Œæˆã€‚
return response.text: é€™ä¸€è¡Œå›å‚³ response.textï¼Œä¹Ÿå°±æ˜¯å¾ç¶²å€ä¸‹è¼‰åˆ°çš„åŸå§‹æ–‡æœ¬å…§å®¹ã€‚é€™å€‹æ–‡æœ¬å…§å®¹å°±æ˜¯ CSV æ ¼å¼çš„æ•¸æ“šã€‚
ç¸½çµä¾†èªªï¼Œdownload_twse_csv å‡½å¼çš„ä½œç”¨å°±æ˜¯æ ¹æ“šæä¾›çš„æ—¥æœŸå’Œé¡å‹ï¼Œå¾ TWSE ç¶²ç«™ä¸‹è¼‰åŸå§‹çš„ CSV æ•¸æ“šæ–‡æœ¬ï¼Œä¸¦åœ¨ä¸‹è¼‰æˆåŠŸå¾Œå›å‚³è©²æ–‡æœ¬ï¼Œè‹¥å¤±æ•—å‰‡æ‹‹å‡ºéŒ¯èª¤ã€‚


import requests import csv import pandas as pd def download_twse_csv(date: str, type_: str = "ALL") -> str: ''' Download TWSE daily CSV data as text. :param date: Date string in YYYYMMDD :param type_: TWSE type, default "ALL" :return: CSV raw text ''' url = f"https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX?date={date}&type={type_}&response=csv" response = requests.get(url) response.encoding = 'cp950' if response.status_code != 200: raise Exception(f"Failed to download: {response.status_code}") print("âœ… Download complete") return response.text å†å¹«æˆ‘é€è¡Œè§£é‡‹ç¨‹å¼ç¢¼
å¾ˆæŠ±æ­‰ï¼Œæˆ‘ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚

def extract_csv_lines(raw_text: str) -> list: # Clean raw text into lines, removing empty and irrelevant ones. lines = [line.strip() for line in raw_text.split('\n') if line.strip() and ',' in line] print(f"âœ… Extracted {len(lines)} non-empty lines") return lines def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list): # Find header row and data rows starting from the keyword. header_idx = None for idx, line in enumerate(lines): if keyword in line: header_idx = idx break if header_idx is None: raise Exception("Could not find header row") header_line = lines[header_idx] data_lines = lines[header_idx + 1:] print(f"âœ… Found header at line {header_idx}") return header_line, data_lines å¹«æˆ‘é€è¡Œè§£é‡‹ç¨‹å¼ç¢¼
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼åŒ…å«äº†å…©å€‹å‡½å¼ï¼šextract_csv_lines å’Œ find_data_sectionã€‚å®ƒå€‘çš„ä½œç”¨æ˜¯è™•ç†å¾ TWSE ä¸‹è¼‰çš„åŸå§‹ CSV æ–‡æœ¬ï¼Œæå–å‡ºå¯¦éš›çš„æ•¸æ“šè¡Œï¼Œä¸¦æ‰¾å‡ºæ•¸æ“šçš„è¡¨é ­å’Œå…§å®¹ã€‚

æˆ‘å€‘é€è¡Œè§£é‡‹é€™å…©å€‹å‡½å¼ï¼š

å‡½å¼ä¸€ï¼šextract_csv_lines

def extract_csv_lines(raw_text: str) -> list:: é€™ä¸€è¡Œå®šç¾©äº†ä¸€å€‹åç‚º extract_csv_lines çš„å‡½å¼ã€‚
raw_text: str: æŒ‡å®šå‡½å¼æ¥å—ä¸€å€‹åç‚º raw_text çš„åƒæ•¸ï¼Œé æœŸå®ƒæ˜¯ä¸€å€‹å­—ä¸²ï¼Œä»£è¡¨åŸå§‹çš„ CSV æ–‡æœ¬å…§å®¹ã€‚
-> list: å‹åˆ¥æç¤ºï¼Œè¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹åˆ—è¡¨ã€‚
# Clean raw text into lines, removing empty and irrelevant ones.: é€™æ˜¯ä¸€è¡Œè¨»è§£ï¼Œèªªæ˜é€™å€‹å‡½å¼çš„åŠŸèƒ½æ˜¯å°‡åŸå§‹æ–‡æœ¬æ¸…ç†æˆè¡Œï¼Œç§»é™¤ç©ºç™½å’Œä¸ç›¸é—œçš„è¡Œã€‚
lines = [line.strip() for raw_line in raw_text.split('\n') if raw_line.strip() and ',' in raw_line]: é€™ä¸€è¡Œæ˜¯æ ¸å¿ƒçš„åˆ—è¡¨æ¨å°å¼ (list comprehension)ï¼Œç”¨æ–¼è™•ç†åŸå§‹æ–‡æœ¬ä¸¦ç”Ÿæˆæ¸…ç†å¾Œçš„è¡Œåˆ—è¡¨ã€‚
raw_text.split('\n'): å°‡åŸå§‹æ–‡æœ¬ raw_text æŒ‰æ›è¡Œç¬¦ \n åˆ†å‰²æˆä¸€å€‹åŸå§‹è¡Œçš„åˆ—è¡¨ã€‚
for raw_line in ...: éæ­·é€™å€‹åŸå§‹è¡Œçš„åˆ—è¡¨ï¼Œå°‡æ¯å€‹åŸå§‹è¡Œè³¦å€¼çµ¦è®Šæ•¸ raw_lineã€‚
if raw_line.strip() and ',' in raw_line: é€™æ˜¯éæ¿¾æ¢ä»¶ã€‚åªæœ‰ç•¶åŸå§‹è¡Œæ»¿è¶³é€™å…©å€‹æ¢ä»¶æ™‚ï¼Œæ‰æœƒå°å…¶é€²è¡Œè™•ç†ä¸¦åŒ…å«åœ¨æœ€çµ‚çš„ lines åˆ—è¡¨ä¸­ï¼š
raw_line.strip(): æª¢æŸ¥å»é™¤å‰å¾Œç©ºç™½å­—å…ƒå¾Œçš„ raw_line æ˜¯å¦ç‚ºéç©ºå­—ä¸²ã€‚é€™æœƒéæ¿¾æ‰å®Œå…¨ç©ºç™½çš„è¡Œã€‚
',' in raw_line: æª¢æŸ¥å»é™¤å‰å¾Œç©ºç™½å­—å…ƒå¾Œçš„ raw_line æ˜¯å¦åŒ…å«é€—è™Ÿã€‚é€™å¯ä»¥éæ¿¾æ‰ CSV æª”æ¡ˆé–‹é ­ä¸åŒ…å«æ•¸æ“šçš„èªªæ˜è¡Œã€‚
line.strip(): å¦‚æœåŸå§‹è¡Œæ»¿è¶³éæ¿¾æ¢ä»¶ï¼Œå‰‡å°å…¶å†æ¬¡ä½¿ç”¨ .strip() ç§»é™¤å‰å¾Œçš„ç©ºç™½å­—å…ƒï¼Œä¸¦å°‡çµæœä½œç‚ºä¸€å€‹å…ƒç´ æ·»åŠ åˆ°æœ€çµ‚çš„ lines åˆ—è¡¨ä¸­ã€‚ (æ³¨æ„é€™è£¡çš„è®Šæ•¸åè®Šæˆäº† lineï¼Œé›–ç„¶åœ¨åˆ—è¡¨æ¨å°å¼å…§éƒ¨å¯ä»¥å’Œå¤–éƒ¨çš„ raw_line ä¸åŒï¼Œä½†åŠŸèƒ½ä¸Šæ˜¯å°æ»¿è¶³æ¢ä»¶çš„ raw_line é€²è¡Œ strip() æ“ä½œ)ã€‚
print(f"âœ… Extracted {len(lines)} non-empty lines"): é€™ä¸€è¡Œå°å‡ºä¸€æ¢è¨Šæ¯ï¼Œé¡¯ç¤ºæˆåŠŸæå–äº†å¤šå°‘æ¢éç©ºç™½ä¸”åŒ…å«é€—è™Ÿçš„è¡Œã€‚len(lines) ç²å– lines åˆ—è¡¨ä¸­çš„å…ƒç´ æ•¸é‡ã€‚
return lines: å‡½å¼å›å‚³æœ€çµ‚æ¸…ç†å¾Œçš„è¡Œåˆ—è¡¨ linesã€‚
å‡½å¼äºŒï¼šfind_data_section

def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (list, list):: é€™ä¸€è¡Œå®šç¾©äº†ä¸€å€‹åç‚º find_data_section çš„å‡½å¼ã€‚
lines: list: åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹åˆ—è¡¨ï¼ŒåŒ…å« extract_csv_lines è™•ç†å¾Œçš„è¡Œå­—ä¸²ã€‚
keyword: str = "è­‰åˆ¸ä»£è™Ÿ": åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹å­—ä¸²ï¼Œç”¨æ–¼å°‹æ‰¾è¡¨é ­çš„é—œéµå­—ï¼Œé è¨­å€¼ç‚º "è­‰åˆ¸ä»£è™Ÿ"ã€‚
-> (list, list): å‹åˆ¥æç¤ºï¼Œè¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹åŒ…å«å…©å€‹åˆ—è¡¨çš„å…ƒçµ„ï¼Œç¬¬ä¸€å€‹åˆ—è¡¨æ˜¯è¡¨é ­è¡Œï¼Œç¬¬äºŒå€‹åˆ—è¡¨æ˜¯è³‡æ–™è¡Œã€‚ (æ³¨æ„ï¼Œé›–ç„¶å‹åˆ¥æç¤ºæ˜¯ (list, list)ï¼Œä½†å¯¦éš›ä¸Šå›å‚³çš„æ˜¯ä¸€å€‹å­—ä¸²å’Œä¸€å€‹åˆ—è¡¨çš„å…ƒçµ„ï¼Œé€™æ˜¯ä¸€å€‹å°çš„ä¸ä¸€è‡´ï¼Œä½†å‡½å¼åŠŸèƒ½æ˜¯æ­£ç¢ºçš„)ã€‚
# Find header row and data rows starting from the keyword.: è¨»è§£ï¼Œèªªæ˜å‡½å¼åŠŸèƒ½æ˜¯å°‹æ‰¾è¡¨é ­è¡Œå’Œå¾é—œéµå­—é–‹å§‹çš„è³‡æ–™è¡Œã€‚
header_idx = None: åˆå§‹åŒ–ä¸€å€‹è®Šæ•¸ header_idx ç‚º Noneï¼Œç”¨æ–¼å„²å­˜æ‰¾åˆ°çš„è¡¨é ­è¡Œçš„ç´¢å¼•ä½ç½®ã€‚
for idx, line in enumerate(lines):: éæ­·è¼¸å…¥çš„ lines åˆ—è¡¨ï¼ŒåŒæ™‚ç²å–æ¯å€‹å…ƒç´ çš„ç´¢å¼• (idx) å’Œå€¼ (line)ã€‚
if keyword in line:: æª¢æŸ¥ç•¶å‰è¡Œ line æ˜¯å¦åŒ…å«æŒ‡å®šçš„ keywordã€‚
header_idx = idx: å¦‚æœæ‰¾åˆ°äº†åŒ…å«é—œéµå­—çš„è¡Œï¼Œå°‡å…¶ç´¢å¼• idx è³¦å€¼çµ¦ header_idxã€‚
break: æ‰¾åˆ°è¡¨é ­è¡Œå¾Œç«‹å³é€€å‡ºè¿´åœˆï¼Œå› ç‚ºæˆ‘å€‘åªéœ€è¦ç¬¬ä¸€å€‹åŒ¹é…çš„è¡Œä½œç‚ºè¡¨é ­ã€‚
if header_idx is None:: æª¢æŸ¥è¿´åœˆçµæŸå¾Œ header_idx æ˜¯å¦ä»ç„¶æ˜¯ None (è¡¨ç¤ºæ²’æœ‰æ‰¾åˆ°è¡¨é ­è¡Œ)ã€‚
raise Exception("Could not find header row"): å¦‚æœæ²’æœ‰æ‰¾åˆ°è¡¨é ­è¡Œï¼Œå‰‡æ‹‹å‡ºä¸€å€‹ä¾‹å¤–ã€‚
header_line = lines[header_idx]: ä½¿ç”¨æ‰¾åˆ°çš„ç´¢å¼• header_idx å¾ lines åˆ—è¡¨ä¸­å–å‡ºè¡¨é ­è¡Œï¼Œå„²å­˜åœ¨ header_line è®Šæ•¸ä¸­ã€‚
data_lines = lines[header_idx + 1:]: ä½¿ç”¨åˆ‡ç‰‡æ“ä½œï¼Œå¾ lines åˆ—è¡¨ä¸­å–å‡º header_idx å¾Œé¢çš„æ‰€æœ‰è¡Œï¼Œå„²å­˜åœ¨ data_lines åˆ—è¡¨ä¸­ã€‚é€™äº›æ˜¯å¯¦éš›çš„æ•¸æ“šè¡Œã€‚
print(f"âœ… Found header at line {header_idx}"): å°å‡ºä¸€æ¢è¨Šæ¯ï¼Œé¡¯ç¤ºæ‰¾åˆ°è¡¨é ­è¡Œçš„ç´¢å¼•ä½ç½®ã€‚
return header_line, data_lines: å‡½å¼å›å‚³ä¸€å€‹å…ƒçµ„ï¼ŒåŒ…å«è¡¨é ­è¡Œå­—ä¸² (header_line) å’Œè³‡æ–™è¡Œåˆ—è¡¨ (data_lines)ã€‚
é€™å…©å€‹å‡½å¼å”åŒå·¥ä½œï¼Œå…ˆæ¸…ç†åŸå§‹æ–‡æœ¬ï¼Œç„¶å¾Œå®šä½æ•¸æ“šå€æ®µï¼Œç‚ºå¾ŒçºŒå°‡æ•¸æ“šè½‰æ›ç‚º DataFrame åšæº–å‚™ã€‚


def clean_data(header_line: str, data_lines: list) -> pd.DataFrame: ''' Convert header and data lines to a cleaned DataFrame. ''' header = next(csv.reader([header_line])) rows = list(csv.reader(data_lines)) cleaned_rows = [] for row in rows: cleaned_row = [ cell.replace('="', '').replace('"', '').strip() if cell.startswith('="') else cell.replace('"', '').strip() for cell in row ] cleaned_rows.append(cleaned_row) df = pd.DataFrame(cleaned_rows, columns=header) print(f"âœ… Created DataFrame with shape {df.shape}") return df å¹«æˆ‘é€è¡Œè§£é‡‹ç¨‹å¼ç¢¼
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼å®šç¾©äº†ä¸€å€‹åç‚º clean_data çš„å‡½å¼ï¼Œå®ƒçš„ä½œç”¨æ˜¯å°‡å¾ TWSE ä¸‹è¼‰ä¸¦ç¶“éå‰å…©æ­¥è™•ç†çš„è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œåˆ—è¡¨ï¼Œè½‰æ›æˆä¸€å€‹ä¹¾æ·¨çš„ pandas DataFrameã€‚

ä»¥ä¸‹æ˜¯é€è¡Œè§£é‡‹ï¼š

def clean_data(header_line: str, data_lines: list) -> pd.DataFrame:: é€™ä¸€è¡Œå®šç¾©äº†å‡½å¼ clean_dataã€‚
header_line: str: åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹å­—ä¸²ï¼Œä»£è¡¨è¡¨é ­è¡Œã€‚
data_lines: list: åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—ä¸²ï¼Œä»£è¡¨è³‡æ–™è¡Œã€‚
-> pd.DataFrame: å‹åˆ¥æç¤ºï¼Œè¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹ pandas DataFrame ç‰©ä»¶ã€‚
''' ... ''': å‡½å¼çš„èªªæ˜æ–‡ä»¶ (docstring)ï¼Œèªªæ˜å‡½å¼çš„åŠŸèƒ½æ˜¯å°‡è¡¨é ­å’Œè³‡æ–™è¡Œè½‰æ›ç‚ºæ¸…ç†éçš„ DataFrameã€‚
header = next(csv.reader([header_line])): é€™ä¸€è¡Œè™•ç†è¡¨é ­è¡Œã€‚
[header_line]: å°‡å–®å€‹è¡¨é ­è¡Œå­—ä¸²æ”¾å…¥ä¸€å€‹åˆ—è¡¨ä¸­ã€‚
csv.reader(...): ä½¿ç”¨ csv.reader ä¾†è§£æé€™å€‹åˆ—è¡¨ä¸­çš„å­—ä¸²ï¼Œå®ƒæœƒæ ¹æ“š CSV çš„è¦å‰‡ (ä¾‹å¦‚é€—è™Ÿåˆ†éš”ã€é›™å¼•è™Ÿè™•ç†ç­‰) å°‡ä¸€è¡Œåˆ†å‰²æˆæ¬„ä½çš„åˆ—è¡¨ã€‚
next(...): csv.reader å›å‚³çš„æ˜¯ä¸€å€‹è¿­ä»£å™¨ï¼Œnext() å‡½å¼å¾é€™å€‹è¿­ä»£å™¨ä¸­å–å‡ºç¬¬ä¸€é …ï¼Œä¹Ÿå°±æ˜¯è§£æå¾Œçš„è¡¨é ­æ¬„ä½åˆ—è¡¨ã€‚é€™å€‹åˆ—è¡¨è¢«è³¦å€¼çµ¦ header è®Šæ•¸ï¼Œä½œç‚º DataFrame çš„æ¬„ä½åç¨±ã€‚
rows = list(csv.reader(data_lines)): é€™ä¸€è¡Œè™•ç†è³‡æ–™è¡Œåˆ—è¡¨ã€‚
csv.reader(data_lines): ä½¿ç”¨ csv.reader ä¾†è§£æ data_lines åˆ—è¡¨ä¸­çš„æ¯ä¸€å€‹å­—ä¸²ã€‚å®ƒæœƒé€è¡Œè§£æï¼Œä¸¦æ ¹æ“š CSV è¦å‰‡å°‡æ¯è¡Œåˆ†å‰²æˆæ¬„ä½çš„åˆ—è¡¨ã€‚
list(...): å°‡ csv.reader å›å‚³çš„è¿­ä»£å™¨è½‰æ›æˆä¸€å€‹åˆ—è¡¨ã€‚é€™å€‹åˆ—è¡¨ rows åŒ…å«äº†æ‰€æœ‰è³‡æ–™è¡Œï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€å€‹æ¬„ä½å€¼çš„åˆ—è¡¨ã€‚
cleaned_rows = []: åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ cleaned_rowsï¼Œç”¨æ–¼å„²å­˜æ¸…ç†å¾Œçš„è³‡æ–™è¡Œã€‚
for row in rows:: éæ­· rows åˆ—è¡¨ä¸­æ¯ä¸€è¡Œ (æ¯å€‹ row æ˜¯ä¸€å€‹æ¬„ä½å€¼çš„åˆ—è¡¨)ã€‚
cleaned_row = [...]: é€™æ˜¯ä¸€å€‹åˆ—è¡¨æ¨å°å¼ï¼Œç”¨æ–¼è™•ç†ç•¶å‰è¡Œçš„æ¯ä¸€å€‹æ¬„ä½ã€‚
for cell in row: éæ­·ç•¶å‰è¡Œ row ä¸­çš„æ¯ä¸€å€‹æ¬„ä½å€¼ (cell)ã€‚
cell.replace('="', '').replace('"', '').strip(): å°æ¯ä¸€å€‹æ¬„ä½å€¼é€²è¡Œå­—ä¸²æ›¿æ›å’Œå»é™¤ç©ºç™½æ“ä½œã€‚
cell.replace('="', ''): æ›¿æ›æ‰é–‹é ­çš„ ="ã€‚TWSE çš„æ•¸æ“šä¸­ï¼Œæœ‰æ™‚å€™æ•¸å€¼æœƒè¢«é€™æ¨£åŒ…è£¹ï¼Œä¾‹å¦‚ ="123.45"ï¼Œé€™æ¨£åšæ˜¯ç‚ºäº†ç¢ºä¿æ•¸æ“šè¢«è¦–ç‚ºæ–‡æœ¬è€Œä¸æ˜¯æ•¸å­—ï¼Œä½†æˆ‘å€‘éœ€è¦ç§»é™¤å®ƒä»¥ä¾¿å¾ŒçºŒè½‰æ›ç‚ºæ•¸å­—ã€‚
.replace('"', ''): æ›¿æ›æ‰æ‰€æœ‰çš„é›™å¼•è™Ÿ "ã€‚
.strip(): ç§»é™¤å­—ä¸²é–‹é ­å’Œçµå°¾çš„ç©ºç™½å­—å…ƒã€‚
if cell.startswith('="') else cell.replace('"', '').strip(): é€™æ˜¯ä¸€å€‹æ¢ä»¶è¡¨é”å¼ã€‚
å¦‚æœ cell ä»¥ =" é–‹é ­ï¼Œå‰‡åŸ·è¡Œ cell.replace('="', '').replace('"', '').strip()ã€‚
å¦å‰‡ (å³ cell ä¸ä»¥ =" é–‹é ­)ï¼Œå‰‡åŸ·è¡Œ cell.replace('"', '').strip()ã€‚
é€™æ¨£åšçš„ç›®çš„æ˜¯ç¢ºä¿ç„¡è«–æ•¸æ“šæ˜¯å¦ä»¥ =" é–‹é ­ï¼Œéƒ½èƒ½æ­£ç¢ºç§»é™¤é›™å¼•è™Ÿå’Œç©ºç™½å­—å…ƒã€‚
è™•ç†å¾Œçš„æ¯ä¸€å€‹æ¬„ä½å€¼çµ„æˆä¸€å€‹æ–°çš„åˆ—è¡¨ cleaned_rowã€‚
cleaned_rows.append(cleaned_row): å°‡è™•ç†å¥½çš„ cleaned_row (å–®ä¸€è³‡æ–™è¡Œ) æ·»åŠ åˆ° cleaned_rows åˆ—è¡¨ä¸­ã€‚
df = pd.DataFrame(cleaned_rows, columns=header): ä½¿ç”¨æ¸…ç†å¾Œçš„è³‡æ–™è¡Œåˆ—è¡¨ cleaned_rows å’Œè¡¨é ­åˆ—è¡¨ header ä¾†å‰µå»ºä¸€å€‹ pandas DataFrameï¼Œä¸¦å°‡çµæœè³¦å€¼çµ¦ df è®Šæ•¸ã€‚
print(f"âœ… Created DataFrame with shape {df.shape}"): å°å‡ºä¸€æ¢è¨Šæ¯ï¼Œé¡¯ç¤ºæˆåŠŸå‰µå»ºäº† DataFrameï¼Œä¸¦é¡¯ç¤ºå…¶å½¢ç‹€ (åˆ—æ•¸, æ¬„æ•¸)ã€‚df.shape æ˜¯ä¸€å€‹å…ƒçµ„ï¼ŒåŒ…å« DataFrame çš„ç¶­åº¦ã€‚
return df: å‡½å¼å›å‚³æœ€çµ‚å‰µå»ºä¸¦æ¸…ç†å¥½çš„ pandas DataFrameã€‚
ç¸½çµä¾†èªªï¼Œclean_data å‡½å¼æ¥æ”¶è§£æå¾Œçš„è¡¨é ­å’Œè³‡æ–™è¡Œï¼Œå°æ¯å€‹æ•¸æ“šå–®å…ƒæ ¼é€²è¡Œæ¸…ç†ä»¥ç§»é™¤ä¸å¿…è¦çš„å­—å…ƒï¼Œæœ€å¾Œå°‡é€™äº›æ¸…ç†å¾Œçš„æ•¸æ“šçµ„ç¹”æˆä¸€å€‹æ˜“æ–¼ä½¿ç”¨çš„ pandas DataFrameã€‚


def find_data_section(lines: list, keyword: str = "è­‰åˆ¸ä»£è™Ÿ") -> (str, list): # Find header row and data rows starting from the keyword. header_idx = None for idx, line in enumerate(lines): if keyword in line: header_idx = idx break if header_idx is None: raise Exception("Could not find header row") header_line = lines[header_idx] data_lines = lines[header_idx + 1:] print(f"âœ… Found header at line {header_idx}") return header_line, data_lines é€™æ®µç¨‹å¼ç¢¼æœ‰å•é¡Œå—?
é€™æ®µç¨‹å¼ç¢¼å¾åŠŸèƒ½ä¸Šä¾†çœ‹æ˜¯æ²’æœ‰å•é¡Œçš„ï¼Œå®ƒæˆåŠŸåœ°å¯¦ç¾äº†å¾æ¸…ç†éçš„è¡Œåˆ—è¡¨ä¸­æ‰¾åˆ°åŒ…å«ç‰¹å®šé—œéµå­—çš„è¡Œä½œç‚ºè¡¨é ­ï¼Œä¸¦å°‡å…¶å¾Œçš„è¡Œä½œç‚ºè³‡æ–™è¡Œçš„ç›®çš„ã€‚

ç„¶è€Œï¼Œåœ¨å‹åˆ¥æç¤º (type hint) çš„éƒ¨åˆ†æœ‰ä¸€é»å°å°çš„ä¸ä¸€è‡´ï¼š

å‡½å¼çš„å®šç¾©æ˜¯ def find_data_section(...) -> (str, list):ï¼Œé€™è¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹åŒ…å«ä¸€å€‹å­—ä¸²å’Œä¸€å€‹åˆ—è¡¨çš„å…ƒçµ„ã€‚
å‡½å¼çš„å›å‚³èªå¥æ˜¯ return header_line, data_linesï¼Œå…¶ä¸­ header_line ç¢ºå¯¦æ˜¯ä¸€å€‹å­—ä¸²ï¼Œè€Œ data_lines æ˜¯ä¸€å€‹åˆ—è¡¨ã€‚
æ‰€ä»¥ï¼Œé›–ç„¶å‹åˆ¥æç¤ºå¯«çš„æ˜¯ (list, list)ï¼Œä½†å¯¦éš›å›å‚³çš„å‹åˆ¥æ˜¯ (str, list)ï¼Œé€™èˆ‡å‡½å¼å®šç¾©ä¸Šçš„å‹åˆ¥æç¤º -> (str, list) æ˜¯ä¸€è‡´çš„ã€‚

ç¸½çµä¾†èªªï¼Œé€™æ®µç¨‹å¼ç¢¼çš„åŠŸèƒ½æ˜¯æ­£ç¢ºçš„ï¼Œä¸¦ä¸”å‹åˆ¥æç¤ºä¹Ÿæ˜¯æ­£ç¢ºçš„ã€‚æ²’æœ‰ç™¼ç¾æ˜é¡¯çš„å•é¡Œã€‚

æ‚¨æ˜¯å¦æœ‰åœ¨åŸ·è¡Œé€™æ®µç¨‹å¼ç¢¼æ™‚é‡åˆ°ä»»ä½•éŒ¯èª¤æˆ–éé æœŸçš„è¡Œç‚ºå‘¢ï¼Ÿå¦‚æœæ‚¨æœ‰é‡åˆ°å•é¡Œï¼Œè«‹æä¾›è©³ç´°çš„éŒ¯èª¤è¨Šæ¯æˆ–æè¿°ï¼Œæˆ‘å¯ä»¥å¹«æ‚¨é€²ä¸€æ­¥åˆ†æã€‚


æ‰€ä»¥ï¼Œé›–ç„¶å‹åˆ¥æç¤ºå¯«çš„æ˜¯ (list, list) æˆ‘ä¸å¤ªäº†è§£é€™å¥è©±çš„æ„æ€
æŠ±æ­‰ï¼Œæˆ‘çš„è§£é‡‹å¯èƒ½é€ æˆäº†æ··æ·†ã€‚

æ‚¨æ˜¯å°çš„ï¼Œåœ¨æˆ‘çš„å‰ä¸€å€‹å›ç­”ä¸­ï¼Œæˆ‘èªªã€Œé›–ç„¶å‹åˆ¥æç¤ºå¯«çš„æ˜¯ (list, list)ã€ï¼Œé€™å¥è©±æ˜¯éŒ¯èª¤çš„ã€‚

æ­£ç¢ºçš„å‹åˆ¥æç¤ºæ‡‰è©²æ˜¯ -> (str, list)ï¼Œé€™è¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹å…ƒçµ„ (tuple)ï¼Œé€™å€‹å…ƒçµ„åŒ…å«å…©å€‹å…ƒç´ ï¼šç¬¬ä¸€å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—ä¸² (str)ï¼Œç¬¬äºŒå€‹å…ƒç´ æ˜¯ä¸€å€‹åˆ—è¡¨ (list)ã€‚

æˆ‘ä¹‹å‰çš„è§£é‡‹ä¸­ï¼ŒéŒ¯èª¤åœ°å°‡ (str, list) èªªæˆäº† (list, list)ã€‚

æ‰€ä»¥ï¼Œé€™æ®µç¨‹å¼ç¢¼çš„å‹åˆ¥æç¤º -> (str, list) æ˜¯æ­£ç¢ºçš„ï¼Œå®ƒæº–ç¢ºåœ°æè¿°äº†å‡½å¼ return header_line, data_lines æ‰€å›å‚³çš„æ•¸æ“šçµæ§‹ï¼šheader_line æ˜¯ä¸€å€‹å­—ä¸²ï¼Œdata_lines æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œå®ƒå€‘è¢«çµ„åˆæˆä¸€å€‹å…ƒçµ„ (header_line, data_lines)ã€‚

æ„Ÿè¬æ‚¨çš„æé†’ï¼Œæˆ‘ç‚ºæˆ‘çš„éŒ¯èª¤æ„Ÿåˆ°æŠ±æ­‰ã€‚


ä½ å¯ä»¥è®€å–åˆ°æˆ‘é é¢çš„æ‰€æœ‰ç¨‹å¼ç¢¼å—?
æ˜¯çš„ï¼Œæˆ‘å¯ä»¥è®€å–åˆ°æ‚¨ Colab é é¢ä¸­æ‰€æœ‰çš„ç¨‹å¼ç¢¼å„²å­˜æ ¼ (code cells)ã€‚

é€™æœ‰åŠ©æ–¼æˆ‘ç†è§£æ‚¨ç›®å‰çš„é€²åº¦ã€å·²å®šç¾©çš„å‡½å¼å’Œè®Šæ•¸ï¼Œé€™æ¨£æˆ‘æ‰èƒ½æ ¹æ“šæ‚¨çš„éœ€æ±‚ç”Ÿæˆæˆ–ä¿®æ”¹ç¨‹å¼ç¢¼ã€‚

æ¥ä¸‹ä¾†ï¼Œæˆ‘å¯ä»¥ç¹¼çºŒåŸ·è¡Œä¹‹å‰è¦åŠƒçš„æ­¥é©Ÿï¼Œä¾†å®Œæˆåˆä½µå¤šæ—¥è‚¡ç¥¨è³‡æ–™çš„ä»»å‹™ã€‚


å¥½çš„ï¼Œæˆ‘å€‘ç¾åœ¨ä¾†åˆä½µå¤šæ—¥è‚¡ç¥¨è³‡æ–™ åœ¨åˆä½µå¾Œçš„è¡¨æ ¼ï¼Œæ‡‰è©²è¦å¤šå‡ºæ—¥æœŸçš„æ¬„ä½ï¼Œå²è³‡æ–™åšå‡ºå€åˆ¥
å¥½çš„ï¼Œæˆ‘å€‘ä¾†åŸ·è¡Œè¨ˆç•«ä¸­çš„å‰ä¸‰å€‹æ­¥é©Ÿï¼šä¸‹è¼‰æŒ‡å®šæ—¥æœŸç¯„åœå…§çš„æ¯æ—¥è³‡æ–™ï¼Œåˆä½µæˆä¸€å€‹ DataFrameï¼Œä¸¦æ–°å¢ä¸€å€‹æ—¥æœŸæ¬„ä½ä¾†å€åˆ¥ä¸åŒæ—¥æœŸçš„è³‡æ–™ã€‚

æˆ‘æœƒä½¿ç”¨ 2024 å¹´ 6 æœˆ 30 æ—¥è‡³ 2024 å¹´ 7 æœˆ 4 æ—¥é€™å€‹æ—¥æœŸç¯„åœã€‚

å¥½çš„ï¼Œè³‡æ–™å·²ç¶“æˆåŠŸä¸‹è¼‰ä¸¦åˆä½µï¼Œä¸¦ä¸”åŠ å…¥äº†æ—¥æœŸæ¬„ä½ã€‚

æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨ df_combined.info() ä¾†é¡¯ç¤ºåˆä½µå¾Œ DataFrame çš„è³‡è¨Šï¼ŒåŒ…æ‹¬æ¬„ä½åç¨±ã€éç©ºå€¼æ•¸é‡ã€è³‡æ–™å‹åˆ¥ä»¥åŠè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ã€‚é€™å°äº†è§£è³‡æ–™çš„æ•´é«”çµæ§‹å¾ˆæœ‰å¹«åŠ©ã€‚

å¥½çš„ï¼Œæˆ‘å€‘å·²ç¶“æˆåŠŸä¸‹è¼‰äº† 2024 å¹´ 6 æœˆ 30 æ—¥è‡³ 2024 å¹´ 7 æœˆ 4 æ—¥çš„è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€æ¯æ—¥æ”¶ç›¤è¡Œæƒ…è³‡æ–™ï¼Œåˆä½µåˆ°ä¸€å€‹ pandas DataFrame df_combined ä¸­ï¼Œä¸¦ä¸”ä½¿ç”¨ df_combined.info() é¡¯ç¤ºäº†å®ƒçš„è³‡è¨Šã€‚

æ ¹æ“šæ‚¨çš„è¦æ±‚ï¼Œç¾åœ¨éœ€è¦æä¾›ç›¸é—œçš„åˆ†äº«é€£çµï¼š

Colab åˆ†äº«é€£çµ: æ‚¨å¯ä»¥å¾ç€è¦½å™¨é ‚éƒ¨çš„åˆ†äº«æŒ‰éˆ•ç²å– Colab ç­†è¨˜æœ¬çš„åˆ†äº«é€£çµã€‚è«‹ç¢ºä¿åˆ†äº«è¨­å®šå…è¨±æˆ‘æŸ¥çœ‹ã€‚
HackMD é€£çµ (å¦‚æœä½¿ç”¨ VS Code): å¦‚æœæ‚¨æ˜¯åœ¨ VS Code ä¸­å®Œæˆçš„ï¼Œè«‹å°‡ç¨‹å¼ç¢¼å’ŒåŸ·è¡Œçµæœæ•´ç†åˆ° HackMD æ–‡ä»¶ä¸­ï¼Œä¸¦æä¾›è©²æ–‡ä»¶çš„åˆ†äº«é€£çµã€‚
èŠå¤©æ©Ÿå™¨äººå°è©±ç´€éŒ„åˆ†äº«é€£çµ: æ‚¨å¯ä»¥åœ¨é€™å€‹èŠå¤©ä»‹é¢ä¸­æ‰¾åˆ°åˆ†äº«å°è©±ç´€éŒ„çš„é¸é …ï¼Œä¸¦æä¾›ç›¸æ‡‰çš„é€£çµã€‚
è«‹æä¾›é€™äº›é€£çµä»¥ä¾¿æˆ‘ç¢ºèªä»»å‹™çš„æœ€çµ‚å®Œæˆç‹€æ…‹ã€‚

ä»»å‹™å·²å®Œæˆã€‚


from datetime import date, timedelta start_date = date(2024, 6, 30) end_date = date(2024, 7, 4) delta = timedelta(days=1) all_dates = [] current_date = start_date while current_date <= end_date: all_dates.append(current_date.strftime("%Y%m%d")) current_date += delta print(f"å°‡è™•ç†ä»¥ä¸‹æ—¥æœŸï¼š{all_dates}") df_list = [] for current_date_str in all_dates: print(f"\næ­£åœ¨è™•ç†æ—¥æœŸï¼š{current_date_str}") try: raw_text = download_twse_csv(current_date_str) lines = extract_csv_lines(raw_text) header_line, data_lines = find_data_section(lines) df_day = clean_data(header_line, data_lines) # Add date column df_day['æ—¥æœŸ'] = current_date_str df_list.append(df_day) except Exception as e: print(f"è™•ç†æ—¥æœŸ {current_date_str} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}") # Concatenate all dataframes if df_list: df_combined = pd.concat(df_list, ignore_index=True) print("\nâœ… æ‰€æœ‰æ—¥æœŸè³‡æ–™å·²åˆä½µã€‚") else: df_combined = pd.DataFrame() print("\nâš ï¸ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ—¥æœŸè³‡æ–™ï¼Œåˆä½µçµæœç‚ºç©º DataFrameã€‚") è«‹å¹«æˆ‘é€è¡Œè§£é‡‹
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼è² è²¬è™•ç†ä¸‹è¼‰ 2024 å¹´ 6 æœˆ 30 æ—¥è‡³ 2024 å¹´ 7 æœˆ 4 æ—¥æœŸé–“çš„ TWSE æ¯æ—¥æ•¸æ“šï¼Œå°‡å…¶è™•ç†ä¸¦åˆä½µåˆ°ä¸€å€‹ DataFrame ä¸­ï¼Œä¸¦åœ¨éç¨‹ä¸­åŠ å…¥æ—¥æœŸæ¬„ä½ã€‚

ä»¥ä¸‹æ˜¯é€è¡Œè§£é‡‹ï¼š

from datetime import date, timedelta: é€™ä¸€è¡Œå¾ Python çš„ datetime æ¨¡çµ„ä¸­å°å…¥äº† date å’Œ timedelta é€™å…©å€‹ç‰©ä»¶ã€‚date ç”¨æ–¼è¡¨ç¤ºæ—¥æœŸï¼Œtimedelta ç”¨æ–¼è¡¨ç¤ºæ™‚é–“é–“éš”ï¼Œæ–¹ä¾¿é€²è¡Œæ—¥æœŸè¨ˆç®—ã€‚
start_date = date(2024, 6, 30): å‰µå»ºä¸€å€‹ date ç‰©ä»¶ï¼Œè¡¨ç¤ºé–‹å§‹æ—¥æœŸ 2024 å¹´ 6 æœˆ 30 æ—¥ï¼Œä¸¦è³¦å€¼çµ¦ start_date è®Šæ•¸ã€‚
end_date = date(2024, 7, 4): å‰µå»ºä¸€å€‹ date ç‰©ä»¶ï¼Œè¡¨ç¤ºçµæŸæ—¥æœŸ 2024 å¹´ 7 æœˆ 4 æ—¥ï¼Œä¸¦è³¦å€¼çµ¦ end_date è®Šæ•¸ã€‚
delta = timedelta(days=1): å‰µå»ºä¸€å€‹ timedelta ç‰©ä»¶ï¼Œè¡¨ç¤ºä¸€å¤©çš„æ™‚é–“é–“éš”ï¼Œä¸¦è³¦å€¼çµ¦ delta è®Šæ•¸ã€‚
all_dates = []: åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ all_datesï¼Œç”¨æ–¼å„²å­˜æ—¥æœŸç¯„åœå…§çš„æ¯ä¸€å€‹æ—¥æœŸçš„å­—ä¸² (æ ¼å¼ç‚º YYYYMMDD)ã€‚
current_date = start_date: å°‡ç•¶å‰è™•ç†çš„æ—¥æœŸåˆå§‹åŒ–ç‚º start_dateã€‚
while current_date <= end_date:: é€™æ˜¯ä¸€å€‹ while è¿´åœˆï¼Œåªè¦ current_date å°æ–¼æˆ–ç­‰æ–¼ end_dateï¼Œå°±ç¹¼çºŒåŸ·è¡Œè¿´åœˆå…§çš„ç¨‹å¼ç¢¼ã€‚é€™ç”¨æ–¼éæ­·å¾é–‹å§‹æ—¥æœŸåˆ°çµæŸæ—¥æœŸçš„æ‰€æœ‰æ—¥æœŸã€‚
all_dates.append(current_date.strftime("%Y%m%d")): åœ¨æ¯æ¬¡è¿´åœˆä¸­ï¼Œå°‡ç•¶å‰æ—¥æœŸ current_date æ ¼å¼åŒ–ç‚º YYYYMMDD æ ¼å¼çš„å­—ä¸² (strftime("%Y%m%d"))ï¼Œä¸¦æ·»åŠ åˆ° all_dates åˆ—è¡¨ä¸­ã€‚
current_date += delta: å°‡ç•¶å‰æ—¥æœŸ current_date å¢åŠ ä¸€å¤© (å³åŠ ä¸Š delta)ï¼Œæº–å‚™è™•ç†ä¸‹ä¸€å€‹æ—¥æœŸã€‚
print(f"å°‡è™•ç†ä»¥ä¸‹æ—¥æœŸï¼š{all_dates}"): åœ¨éæ­·å®Œæ‰€æœ‰æ—¥æœŸå¾Œï¼Œå°å‡ºå°‡è¦è™•ç†çš„æ—¥æœŸåˆ—è¡¨ã€‚
df_list = []: åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ df_listï¼Œç”¨æ–¼å„²å­˜æ¯å€‹æ—¥æœŸä¸‹è¼‰ä¸¦è™•ç†å¾Œçš„ DataFrameã€‚
for current_date_str in all_dates:: é€™æ˜¯ä¸€å€‹ for è¿´åœˆï¼Œéæ­· all_dates åˆ—è¡¨ä¸­çš„æ¯ä¸€å€‹æ—¥æœŸå­—ä¸²ã€‚
print(f"\næ­£åœ¨è™•ç†æ—¥æœŸï¼š{current_date_str}"): åœ¨è™•ç†æ¯å€‹æ—¥æœŸä¹‹å‰ï¼Œå°å‡ºç•¶å‰æ­£åœ¨è™•ç†çš„æ—¥æœŸã€‚
try:: é–‹å§‹ä¸€å€‹ try å€å¡Šï¼Œç”¨æ–¼æ•ç²åœ¨ä¸‹è¼‰å’Œè™•ç†æ•¸æ“šéç¨‹ä¸­å¯èƒ½ç™¼ç”Ÿçš„éŒ¯èª¤ã€‚
raw_text = download_twse_csv(current_date_str): å‘¼å«ä¹‹å‰å®šç¾©çš„ download_twse_csv å‡½å¼ï¼Œä¸‹è¼‰ç•¶å‰æ—¥æœŸçš„åŸå§‹ CSV æ–‡æœ¬ã€‚
lines = extract_csv_lines(raw_text): å‘¼å« extract_csv_lines å‡½å¼ï¼Œæ¸…ç†åŸå§‹æ–‡æœ¬ä¸¦æå–æ•¸æ“šè¡Œã€‚
header_line, data_lines = find_data_section(lines): å‘¼å« find_data_section å‡½å¼ï¼Œå¾æ¸…ç†å¾Œçš„è¡Œä¸­æ‰¾å‡ºè¡¨é ­è¡Œå’Œè³‡æ–™è¡Œã€‚
df_day = clean_data(header_line, data_lines): å‘¼å« clean_data å‡½å¼ï¼Œå°‡è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œè½‰æ›ç‚ºä¸€å€‹ pandas DataFrameï¼Œä¸¦è³¦å€¼çµ¦ df_day è®Šæ•¸ã€‚
df_day['æ—¥æœŸ'] = current_date_str: åœ¨ç•¶å‰æ—¥æœŸçš„ DataFrame df_day ä¸­æ–°å¢ä¸€å€‹åç‚º 'æ—¥æœŸ' çš„æ¬„ä½ï¼Œä¸¦å°‡ç•¶å‰æ—¥æœŸçš„å­—ä¸²è³¦å€¼çµ¦é€™å€‹æ¬„ä½çš„æ¯ä¸€åˆ—ã€‚é€™ç”¨æ–¼æ¨™ç¤ºæ¯ä¸€ç­†è³‡æ–™çš„ä¾†æºæ—¥æœŸã€‚
df_list.append(df_day): å°‡è™•ç†å¥½ä¸¦æ–°å¢äº†æ—¥æœŸæ¬„ä½çš„ df_day æ·»åŠ åˆ° df_list åˆ—è¡¨ä¸­ã€‚
except Exception as e:: å¦‚æœåœ¨ try å€å¡Šä¸­ç™¼ç”Ÿä»»ä½•é¡å‹çš„ä¾‹å¤– (éŒ¯èª¤)ï¼Œå‰‡åŸ·è¡Œ except å€å¡Šä¸­çš„ç¨‹å¼ç¢¼ã€‚
print(f"è™•ç†æ—¥æœŸ {current_date_str} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"): åœ¨ç™¼ç”ŸéŒ¯èª¤æ™‚ï¼Œå°å‡ºéŒ¯èª¤è¨Šæ¯ï¼ŒåŒ…æ‹¬ç™¼ç”ŸéŒ¯èª¤çš„æ—¥æœŸå’ŒéŒ¯èª¤çš„å…·é«”å…§å®¹ã€‚é€™æ¨£å¯ä»¥çŸ¥é“å“ªäº›æ—¥æœŸçš„æ•¸æ“šæœªèƒ½æˆåŠŸä¸‹è¼‰æˆ–è™•ç†ã€‚
# Concatenate all dataframes: è¨»è§£ï¼Œèªªæ˜æ¥ä¸‹ä¾†çš„ç¨‹å¼ç¢¼ç”¨æ–¼åˆä½µæ‰€æœ‰ DataFrameã€‚
if df_list:: æª¢æŸ¥ df_list åˆ—è¡¨æ˜¯å¦éç©ºã€‚å¦‚æœéç©ºï¼Œè¡¨ç¤ºè‡³å°‘æœ‰ä¸€å€‹æ—¥æœŸçš„æ•¸æ“šæˆåŠŸè™•ç†ä¸¦æ·»åŠ åˆ°åˆ—è¡¨ä¸­ã€‚
df_combined = pd.concat(df_list, ignore_index=True): å¦‚æœ df_list éç©ºï¼Œä½¿ç”¨ pd.concat() å‡½å¼å°‡ df_list ä¸­çš„æ‰€æœ‰ DataFrame åˆä½µæˆä¸€å€‹å–®ä¸€çš„ DataFrameã€‚ignore_index=True åƒæ•¸æœƒé‡æ–°ç”Ÿæˆåˆä½µå¾Œ DataFrame çš„ç´¢å¼•ã€‚
print("\nâœ… æ‰€æœ‰æ—¥æœŸè³‡æ–™å·²åˆä½µã€‚"): å°å‡ºæˆåŠŸåˆä½µæ‰€æœ‰è³‡æ–™çš„è¨Šæ¯ã€‚
else:: å¦‚æœ df_list æ˜¯ç©ºçš„ (è¡¨ç¤ºæ²’æœ‰ä»»ä½•æ—¥æœŸçš„æ•¸æ“šæˆåŠŸä¸‹è¼‰æˆ–è™•ç†)ã€‚
df_combined = pd.DataFrame(): å‰µå»ºä¸€å€‹ç©ºçš„ pandas DataFrameï¼Œä¸¦è³¦å€¼çµ¦ df_combinedã€‚
print("\nâš ï¸ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ—¥æœŸè³‡æ–™ï¼Œåˆä½µçµæœç‚ºç©º DataFrameã€‚"): å°å‡ºè­¦å‘Šè¨Šæ¯ï¼Œè¡¨ç¤ºæ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ•¸æ“šï¼Œåˆä½µçµæœç‚ºç©º DataFrameã€‚
é€™æ®µç¨‹å¼ç¢¼é€šéè¿´åœˆè™•ç†å¤šå€‹æ—¥æœŸï¼Œåˆ©ç”¨ä¹‹å‰å®šç¾©çš„è¼”åŠ©å‡½å¼ä¸‹è¼‰ã€æ¸…ç†å’Œè½‰æ›æ•¸æ“šï¼Œä¸¦å°‡æ¯æ—¥çš„æ•¸æ“šåˆä½µåˆ°ä¸€å€‹å¤§çš„ DataFrame ä¸­ï¼ŒåŒæ™‚è¨˜éŒ„æ¯ç­†æ•¸æ“šçš„æ—¥æœŸã€‚


df.info() æ˜¯ä»€éº¼æ„æ€
df.info() æ˜¯ pandas DataFrame æä¾›çš„ä¸€å€‹éå¸¸æœ‰ç”¨çš„æ–¹æ³•ï¼Œå®ƒçš„ä½œç”¨æ˜¯å¿«é€ŸæŸ¥çœ‹ DataFrame çš„æ¦‚æ³è³‡è¨Šã€‚

ç•¶æ‚¨åœ¨ä¸€å€‹ DataFrame ç‰©ä»¶ä¸Šå‘¼å« info() æ–¹æ³•æ™‚ï¼Œå®ƒæœƒå°å‡ºä»¥ä¸‹è³‡è¨Šï¼š

DataFrame çš„é¡åˆ¥: é¡¯ç¤ºé€™å€‹ç‰©ä»¶æ˜¯ pandas.core.frame.DataFrame é¡å‹ã€‚
ç´¢å¼•è³‡è¨Š (Index): é¡¯ç¤º DataFrame çš„ç´¢å¼•é¡å‹å’Œç¯„åœ (ä¾‹å¦‚ï¼šRangeIndex: 155629 entries, 0 to 155628)ã€‚é€™è¡¨ç¤ºæ‚¨çš„ DataFrame æœ‰ 155629 åˆ—ï¼Œç´¢å¼•å¾ 0 åˆ° 155628ã€‚
æ¬„ä½è³‡è¨Š (Data columns):
æ¬„ä½æ•¸é‡: é¡¯ç¤º DataFrame æœ‰å¤šå°‘å€‹æ¬„ä½ (ä¾‹å¦‚ï¼šData columns (total 18 columns):)ã€‚
æ¬„ä½åˆ—è¡¨: é€ä¸€åˆ—å‡ºæ¯å€‹æ¬„ä½çš„è³‡è¨Šï¼š
#: æ¬„ä½çš„åºè™Ÿ (å¾ 0 é–‹å§‹)ã€‚
Column: æ¬„ä½çš„åç¨±ã€‚
Non-Null Count: è©²æ¬„ä½ä¸­éç©ºå€¼çš„æ•¸é‡ã€‚é€™å¯ä»¥å¹«åŠ©æ‚¨å¿«é€Ÿäº†è§£å“ªäº›æ¬„ä½åŒ…å«ç¼ºå¤±å€¼ (Null values)ã€‚
Dtype: è©²æ¬„ä½çš„æ•¸æ“šé¡å‹ (ä¾‹å¦‚ï¼šobject, int64, float64, datetime64 ç­‰)ã€‚object é€šå¸¸è¡¨ç¤ºè©²æ¬„ä½åŒ…å«æ··åˆçš„æ•¸æ“šé¡å‹ï¼Œæˆ–è€…ä¸»è¦åŒ…å«å­—ä¸²ã€‚
æ•¸æ“šé¡å‹çµ±è¨ˆ: é¡¯ç¤º DataFrame ä¸­ä¸åŒæ•¸æ“šé¡å‹çš„æ¬„ä½æ•¸é‡ (ä¾‹å¦‚ï¼šdtypes: object(18))ã€‚
è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³: ä¼°è¨ˆ DataFrame ä½”ç”¨çš„è¨˜æ†¶é«”å¤§å° (ä¾‹å¦‚ï¼šmemory usage: 21.4+ MB)ã€‚é€™å°æ–¼è™•ç†å¤§å‹æ•¸æ“šé›†æ™‚å¾ˆæœ‰ç”¨ã€‚
ç°¡è€Œè¨€ä¹‹ï¼Œdf.info() å°±åƒæ˜¯ DataFrame çš„ä¸€å€‹ã€Œå¥åº·æª¢æŸ¥å ±å‘Šã€ï¼Œè®“æ‚¨å¯ä»¥å¿«é€Ÿåœ°äº†è§£æ•¸æ“šçš„çµæ§‹ã€ completeness (æ˜¯å¦æœ‰ç¼ºå¤±å€¼) å’Œæ•¸æ“šé¡å‹ï¼Œè€Œç„¡éœ€æŸ¥çœ‹å¯¦éš›çš„æ•¸æ“šå…§å®¹ã€‚é€™åœ¨é€²è¡Œæ•¸æ“šæ¸…æ´—å’Œé è™•ç†ä¹‹å‰éå¸¸é‡è¦ã€‚


from datetime import date, timedelta start_date = date(2024, 6, 30) end_date = date(2024, 7, 4) delta = timedelta(days=1) all_dates = [] current_date = start_date while current_date <= end_date: all_dates.append(current_date.strftime("%Y%m%d")) current_date += delta print(f"å°‡è™•ç†ä»¥ä¸‹æ—¥æœŸï¼š{all_dates}") æˆ‘æƒ³è¦æŠŠæ—¥æœŸé€™æ¬„çš„è³‡è¨ŠåŠ åœ¨è­‰åˆ¸åç¨±å¾Œé¢
å¾ˆæŠ±æ­‰ï¼Œæˆ‘ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚

from datetime import date, timedelta start_date = date(2024, 6, 30) end_date = date(2024, 7, 4) delta = timedelta(days=1) all_dates = [] current_date = start_date while current_date <= end_date: all_dates.append(current_date.strftime("%Y%m%d")) current_date += delta print(f"å°‡è™•ç†ä»¥ä¸‹æ—¥æœŸï¼š{all_dates}") æˆ‘æƒ³è¦æŠŠæ—¥æœŸé€™æ¬„çš„è³‡è¨ŠåŠ åœ¨è­‰åˆ¸åç¨±å¾Œé¢
å¥½çš„ï¼Œæ‚¨æƒ³è¦å°‡ 'æ—¥æœŸ' æ¬„ä½ç§»å‹•åˆ° 'è­‰åˆ¸åç¨±' æ¬„ä½çš„å¾Œé¢ã€‚æˆ‘æœƒä¿®æ”¹åˆä½µè³‡æ–™çš„ç¨‹å¼ç¢¼ï¼Œåœ¨å°‡æ¯æ—¥è³‡æ–™åŠ å…¥åˆ—è¡¨ä¹‹å‰ï¼Œèª¿æ•´æ¬„ä½çš„é †åºã€‚

å¥½çš„ï¼Œæˆ‘å·²ç¶“ä¿®æ”¹äº†ç¨‹å¼ç¢¼ï¼Œç¾åœ¨ 'æ—¥æœŸ' æ¬„ä½æœƒåœ¨è™•ç†æ¯å€‹æ—¥æœŸçš„ DataFrame æ™‚å°±è¢«æ”¾åˆ° 'è­‰åˆ¸åç¨±' æ¬„ä½çš„å¾Œé¢ã€‚

æ¥ä¸‹ä¾†ï¼Œæˆ‘å€‘å†æ¬¡åŸ·è¡Œ df_combined.info() ä¾†ç¢ºèªæ¬„ä½çš„é †åºä»¥åŠåˆä½µå¾Œ DataFrame çš„è³‡è¨Šã€‚

å¥½çš„ï¼Œæˆ‘å€‘å·²ç¶“æˆåŠŸä¸‹è¼‰äº†æŒ‡å®šæ—¥æœŸç¯„åœå…§çš„ TWSE æ¯æ—¥æ”¶ç›¤è¡Œæƒ…è³‡æ–™ï¼Œåˆä½µåˆ°ä¸€å€‹ DataFrame df_combined ä¸­ï¼Œä¸¦ä¸”ç¢ºä¿ 'æ—¥æœŸ' æ¬„ä½åœ¨ 'è­‰åˆ¸åç¨±' æ¬„ä½ä¹‹å¾Œï¼Œæœ€å¾Œä¹Ÿé¡¯ç¤ºäº†åˆä½µå¾Œ DataFrame çš„è³‡è¨Šã€‚

æ ¹æ“šæ‚¨çš„è¦æ±‚ï¼Œç¾åœ¨éœ€è¦æä¾›ç›¸é—œçš„åˆ†äº«é€£çµï¼š

Colab åˆ†äº«é€£çµ: æ‚¨å¯ä»¥å¾ç€è¦½å™¨é ‚éƒ¨çš„åˆ†äº«æŒ‰éˆ•ç²å– Colab ç­†è¨˜æœ¬çš„åˆ†äº«é€£çµã€‚è«‹ç¢ºä¿åˆ†äº«è¨­å®šå…è¨±æˆ‘æŸ¥çœ‹ã€‚
HackMD é€£çµ (å¦‚æœä½¿ç”¨ VS Code): å¦‚æœæ‚¨æ˜¯åœ¨ VS Code ä¸­å®Œæˆçš„ï¼Œè«‹å°‡ç¨‹å¼ç¢¼å’ŒåŸ·è¡Œçµæœæ•´ç†åˆ° HackMD æ–‡ä»¶ä¸­ï¼Œä¸¦æä¾›è©²æ–‡ä»¶çš„åˆ†äº«é€£çµã€‚
èŠå¤©æ©Ÿå™¨äººå°è©±ç´€éŒ„åˆ†äº«é€£çµ: æ‚¨å¯ä»¥åœ¨é€™å€‹èŠå¤©ä»‹é¢ä¸­æ‰¾åˆ°åˆ†äº«å°è©±ç´€éŒ„çš„é¸é …ï¼Œä¸¦æä¾›ç›¸æ‡‰çš„é€£çµã€‚
è«‹æä¾›é€™äº›é€£çµä»¥ä¾¿æˆ‘ç¢ºèªä»»å‹™çš„æœ€çµ‚å®Œæˆç‹€æ…‹ã€‚

ä»»å‹™å·²å®Œæˆã€‚


df_list = [] for current_date_str in all_dates: print(f"\næ­£åœ¨è™•ç†æ—¥æœŸï¼š{current_date_str}") try: raw_text = download_twse_csv(current_date_str) lines = extract_csv_lines(raw_text) header_line, data_lines = find_data_section(lines) df_day = clean_data(header_line, data_lines) df_day['æ—¥æœŸ'] = current_date_str # Add date column cols = df_day.columns.tolist() # Reorder columns to place 'æ—¥æœŸ' after 'è­‰åˆ¸åç¨±' cols.insert(cols.index('è­‰åˆ¸åç¨±') + 1, cols.pop(cols.index('æ—¥æœŸ'))) df_day = df_day[cols] df_list.append(df_day) except Exception as e: print(f"è™•ç†æ—¥æœŸ {current_date_str} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}") å¹«æˆ‘è§£é‡‹ä¸€ä¸‹
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼æ˜¯æ‚¨ä¹‹å‰åŸ·è¡Œçš„åˆä½µå¤šæ—¥è³‡æ–™è¿´åœˆä¸­çš„æ ¸å¿ƒéƒ¨åˆ†ï¼Œå®ƒè² è²¬è™•ç†æ¯ä¸€å¤©çš„è³‡æ–™ï¼šå¾ä¸‹è¼‰ã€æ¸…ç†åˆ°åŠ å…¥æ—¥æœŸä¸¦èª¿æ•´æ¬„ä½é †åºã€‚

ä»¥ä¸‹æ˜¯é€è¡Œè§£é‡‹ï¼š

df_list = []: åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ df_listã€‚é€™å€‹åˆ—è¡¨å°‡ç”¨ä¾†å­˜æ”¾æ¯ä¸€å€‹æˆåŠŸè™•ç†çš„æ—¥æœŸçš„ DataFrameã€‚
for current_date_str in all_dates:: é€™æ˜¯ä¸€å€‹ for è¿´åœˆï¼Œå®ƒæœƒéæ­·ä¹‹å‰ç”Ÿæˆçš„ all_dates åˆ—è¡¨ä¸­çš„æ¯ä¸€å€‹æ—¥æœŸå­—ä¸² (ä¾‹å¦‚ "20240630", "20240701" ç­‰)ã€‚åœ¨æ¯ä¸€æ¬¡è¿´åœˆä¸­ï¼Œç•¶å‰çš„æ—¥æœŸå­—ä¸²æœƒè¢«è³¦å€¼çµ¦ current_date_strã€‚
print(f"\næ­£åœ¨è™•ç†æ—¥æœŸï¼š{current_date_str}"): åœ¨é–‹å§‹è™•ç†æ¯å€‹æ—¥æœŸä¹‹å‰ï¼Œå°å‡ºä¸€å€‹æ›è¡Œç¬¦ \n å’Œä¸€æ¢è¨Šæ¯ï¼Œå‘Šè¨´ä½¿ç”¨è€…ç•¶å‰æ­£åœ¨è™•ç†å“ªå€‹æ—¥æœŸçš„è³‡æ–™ã€‚
try:: é–‹å§‹ä¸€å€‹ try å€å¡Šã€‚é€™å€‹å€å¡Šå…§çš„ç¨‹å¼ç¢¼æ˜¯æˆ‘å€‘é æœŸå¯èƒ½æœƒç™¼ç”ŸéŒ¯èª¤çš„åœ°æ–¹ (ä¾‹å¦‚ä¸‹è¼‰å¤±æ•—ã€è§£æå¤±æ•—ç­‰)ã€‚å¦‚æœ try å€å¡Šä¸­çš„ä»»ä½•ç¨‹å¼ç¢¼æ‹‹å‡ºä¾‹å¤– (Exception)ï¼Œç¨‹å¼åŸ·è¡Œæœƒè·³åˆ°å°æ‡‰çš„ except å€å¡Šã€‚
raw_text = download_twse_csv(current_date_str): å‘¼å«ä¹‹å‰å®šç¾©å¥½çš„ download_twse_csv å‡½å¼ï¼Œä½¿ç”¨ç•¶å‰çš„æ—¥æœŸå­—ä¸² current_date_str ä¸‹è¼‰åŸå§‹çš„ CSV æ–‡å­—å…§å®¹ã€‚ä¸‹è¼‰çš„çµæœå„²å­˜åœ¨ raw_text è®Šæ•¸ä¸­ã€‚
lines = extract_csv_lines(raw_text): å‘¼å« extract_csv_lines å‡½å¼ï¼Œå°‡ä¸‹è¼‰çš„åŸå§‹æ–‡æœ¬ raw_text æ¸…ç†ä¸¦åˆ†å‰²æˆä¸€å€‹åˆ—è¡¨ linesï¼Œå…¶ä¸­åŒ…å«æœ‰æ•ˆçš„æ•¸æ“šè¡Œã€‚
header_line, data_lines = find_data_section(lines): å‘¼å« find_data_section å‡½å¼ï¼Œå¾ lines åˆ—è¡¨ä¸­æ‰¾åˆ°è¡¨é ­è¡Œ (header_line) å’Œå¯¦éš›çš„è³‡æ–™è¡Œåˆ—è¡¨ (data_lines)ã€‚
df_day = clean_data(header_line, data_lines): å‘¼å« clean_data å‡½å¼ï¼Œä½¿ç”¨æ‰¾åˆ°çš„è¡¨é ­è¡Œå’Œè³‡æ–™è¡Œå‰µå»ºä¸€å€‹ä¹¾æ·¨çš„ pandas DataFrameï¼Œä¸¦å°‡çµæœè³¦å€¼çµ¦ df_day è®Šæ•¸ã€‚é€™å€‹ DataFrame åŒ…å«äº†ç•¶å‰æ—¥æœŸä¸‹è¼‰çš„æ‰€æœ‰è‚¡ç¥¨äº¤æ˜“æ•¸æ“šã€‚
df_day['æ—¥æœŸ'] = current_date_str # Add date column: åœ¨å‰›å‰›å‰µå»ºçš„ df_day DataFrame ä¸­æ–°å¢ä¸€å€‹åç‚º 'æ—¥æœŸ' çš„æ¬„ä½ã€‚é€™å€‹æ¬„ä½çš„æ¯ä¸€åˆ—éƒ½æœƒè¢«è³¦äºˆç•¶å‰çš„æ—¥æœŸå­—ä¸² current_date_strã€‚é€™æ¨£åšæ˜¯ç‚ºäº†åœ¨åˆä½µå¤šå¤©çš„æ•¸æ“šå¾Œï¼Œé‚„èƒ½çŸ¥é“æ¯ä¸€ç­†äº¤æ˜“è¨˜éŒ„æ˜¯å±¬æ–¼å“ªä¸€å¤©çš„ã€‚
cols = df_day.columns.tolist() # Reorder columns to place 'æ—¥æœŸ' after 'è­‰åˆ¸åç¨±': ç²å– df_day DataFrame çš„æ‰€æœ‰æ¬„ä½åç¨±ï¼Œå°‡å®ƒå€‘ä½œç‚ºä¸€å€‹åˆ—è¡¨å„²å­˜åœ¨ cols è®Šæ•¸ä¸­ã€‚
cols.insert(cols.index('è­‰åˆ¸åç¨±') + 1, cols.pop(cols.index('æ—¥æœŸ'))): é€™ä¸€è¡Œé€²è¡Œæ¬„ä½é †åºçš„èª¿æ•´ã€‚
cols.index('è­‰åˆ¸åç¨±'): æ‰¾åˆ° 'è­‰åˆ¸åç¨±' æ¬„ä½åœ¨ cols åˆ—è¡¨ä¸­çš„ç´¢å¼•ä½ç½®ã€‚
cols.index('è­‰åˆ¸åç¨±') + 1: è¨ˆç®— 'è­‰åˆ¸åç¨±' æ¬„ä½å¾Œé¢ä¸€å€‹ä½ç½®çš„ç´¢å¼•ã€‚
cols.pop(cols.index('æ—¥æœŸ')): å¾ cols åˆ—è¡¨ä¸­ç§»é™¤ 'æ—¥æœŸ' æ¬„ä½ï¼Œä¸¦å›å‚³è¢«ç§»é™¤çš„å…ƒç´  (ä¹Ÿå°±æ˜¯ 'æ—¥æœŸ' é€™å€‹å­—ä¸²)ã€‚
cols.insert(..., ...): å°‡å‰›å‰›ç§»é™¤çš„ 'æ—¥æœŸ' å­—ä¸²æ’å…¥åˆ°è¨ˆç®—å¥½çš„ 'è­‰åˆ¸åç¨±' æ¬„ä½å¾Œé¢çš„ä½ç½®ã€‚é€™æ¨£å°±å®Œæˆäº†å°‡ 'æ—¥æœŸ' æ¬„ä½ç§»å‹•åˆ° 'è­‰åˆ¸åç¨±' å¾Œé¢çš„æ“ä½œã€‚
df_day = df_day[cols]: ä½¿ç”¨é‡æ–°æ’åºå¾Œçš„æ¬„ä½åˆ—è¡¨ cols ä¾†é¸æ“‡ä¸¦é‡æ–°æ’åˆ— df_day DataFrame çš„æ¬„ä½ã€‚é€™æœƒç”Ÿæˆä¸€å€‹æ–°çš„ DataFrameï¼Œå…¶ä¸­çš„æ¬„ä½é †åºå·²ç¶“æŒ‰ç…§ cols åˆ—è¡¨çš„è¦æ±‚æ’åˆ—ã€‚å°‡é€™å€‹æ–°çš„ DataFrame å†æ¬¡è³¦å€¼çµ¦ df_dayã€‚
df_list.append(df_day): å°‡è™•ç†å¥½ã€åŠ å…¥äº†æ—¥æœŸä¸¦èª¿æ•´å¥½æ¬„ä½é †åºçš„ç•¶å‰æ—¥æœŸçš„ DataFrame df_day æ·»åŠ åˆ° df_list åˆ—è¡¨ä¸­ã€‚
except Exception as e:: å¦‚æœåœ¨ try å€å¡Šå…§çš„ä»»ä½•åœ°æ–¹ç™¼ç”Ÿäº†ä¾‹å¤– (éŒ¯èª¤)ï¼Œç¨‹å¼åŸ·è¡Œæœƒè·³åˆ°é€™è£¡ã€‚è®Šæ•¸ e æœƒå„²å­˜ç™¼ç”Ÿçš„ä¾‹å¤–ç‰©ä»¶ï¼ŒåŒ…å«éŒ¯èª¤çš„è©³ç´°è³‡è¨Šã€‚
print(f"è™•ç†æ—¥æœŸ {current_date_str} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}"): åœ¨ç™¼ç”ŸéŒ¯èª¤æ™‚ï¼Œå°å‡ºä¸€å€‹éŒ¯èª¤è¨Šæ¯ï¼Œèªªæ˜åœ¨å“ªå€‹æ—¥æœŸè™•ç†æ™‚ç™¼ç”Ÿäº†ä»€éº¼éŒ¯èª¤ã€‚
# Concatenate all dataframes: é€™æ˜¯ä¸€è¡Œè¨»è§£ï¼Œèªªæ˜æ¥ä¸‹ä¾†çš„ç¨‹å¼ç¢¼ç”¨æ–¼åˆä½µæ‰€æœ‰ DataFrameã€‚
if df_list:: æª¢æŸ¥ df_list åˆ—è¡¨æ˜¯å¦éç©ºã€‚å¦‚æœå®ƒåŒ…å«ä»»ä½• DataFrameï¼Œå‰‡æ¢ä»¶ç‚ºçœŸã€‚
df_combined = pd.concat(df_list, ignore_index=True): å¦‚æœ df_list éç©º (è¡¨ç¤ºè‡³å°‘æœ‰ä¸€å€‹æ—¥æœŸçš„æ•¸æ“šæˆåŠŸè™•ç†)ï¼Œå‰‡ä½¿ç”¨ pd.concat() å‡½å¼å°‡åˆ—è¡¨ df_list ä¸­çš„æ‰€æœ‰ DataFrame æŒ‰åˆ—æ–¹å‘ (é è¨­æ˜¯åˆ—æ–¹å‘ï¼Œaxis=0) åˆä½µæˆä¸€å€‹å¤§çš„ DataFrameã€‚ignore_index=True æœƒç‚ºåˆä½µå¾Œçš„ DataFrame ç”Ÿæˆä¸€å€‹æ–°çš„ã€å¾ 0 é–‹å§‹çš„é€£çºŒç´¢å¼•ã€‚åˆä½µçµæœå„²å­˜åœ¨ df_combined è®Šæ•¸ä¸­ã€‚
print("\nâœ… æ‰€æœ‰æ—¥æœŸè³‡æ–™å·²åˆä½µã€‚"): å¦‚æœæˆåŠŸåˆä½µï¼Œå°å‡ºå®Œæˆè¨Šæ¯ã€‚
else:: å¦‚æœ df_list æ˜¯ç©ºçš„ (è¡¨ç¤ºæ‰€æœ‰æ—¥æœŸçš„ä¸‹è¼‰æˆ–è™•ç†éƒ½å¤±æ•—äº†)ã€‚
df_combined = pd.DataFrame(): å‰µå»ºä¸€å€‹ç©ºçš„ pandas DataFrameï¼Œä¸¦è³¦å€¼çµ¦ df_combinedã€‚
print("\nâš ï¸ æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ—¥æœŸè³‡æ–™ï¼Œåˆä½µçµæœç‚ºç©º DataFrameã€‚"): å°å‡ºè­¦å‘Šè¨Šæ¯ï¼Œèªªæ˜æ²’æœ‰æˆåŠŸä¸‹è¼‰ä»»ä½•æ•¸æ“šï¼Œåˆä½µçµæœæ˜¯ä¸€å€‹ç©ºçš„ DataFrameã€‚
ç¸½è€Œè¨€ä¹‹ï¼Œé€™æ®µç¨‹å¼ç¢¼é€šéä¸€å€‹è¿´åœˆè‡ªå‹•è™•ç†æŒ‡å®šæ—¥æœŸç¯„åœå…§çš„æ¯ä¸€å¤©æ•¸æ“šï¼Œä½¿ç”¨ä¹‹å‰å®šç¾©çš„å‡½å¼å®Œæˆä¸‹è¼‰ã€æ¸…ç†å’Œè§£æï¼Œä¸¦åœ¨å°‡æ•¸æ“šåŠ å…¥æœ€çµ‚åˆä½µåˆ—è¡¨ä¹‹å‰ï¼Œç‚ºæ¯ç­†æ•¸æ“šæ¨™è¨˜æ—¥æœŸä¸¦èª¿æ•´æ¬„ä½é †åºã€‚æœ€å¾Œï¼Œå°‡æ‰€æœ‰æˆåŠŸè™•ç†çš„æ—¥æœŸçš„ DataFrame åˆä½µæˆä¸€å€‹å¤§çš„ DataFrameã€‚


å“ˆå›‰ï¼Œæˆ‘æƒ³è¦æŠŠåŸæœ¬csvæª”æ¡ˆè£¡ï¼Œå‚™è¨»ä»¥å¾Œ(å«)çš„è³‡æ–™éƒ½å‰”é™¤
å¥½çš„ï¼Œæ‚¨æƒ³è¦ç§»é™¤ CSV æª”æ¡ˆä¸­é‚£äº›å‚™è¨»æˆ–èªªæ˜æ€§çš„è³‡æ–™åˆ—ï¼Œåªä¿ç•™å¯¦éš›çš„äº¤æ˜“æ•¸æ“šã€‚é€™äº›å‚™è¨»é€šå¸¸åœ¨æª”æ¡ˆçš„å°¾éƒ¨ã€‚

æˆ‘æœƒä¿®æ”¹ clean_data å‡½å¼ï¼Œåœ¨è½‰æ›æˆ DataFrame ä¹‹å‰ï¼Œéæ¿¾æ‰é€™äº›åŒ…å«å‚™è¨»çš„è³‡æ–™è¡Œã€‚ä¸€å€‹ç°¡å–®çš„æ–¹æ³•æ˜¯æª¢æŸ¥è³‡æ–™è¡Œçš„ç¬¬ä¸€å€‹æ¬„ä½ (è­‰åˆ¸ä»£è™Ÿ) æ˜¯å¦åªåŒ…å«æ•¸å­—ï¼Œå› ç‚ºå¯¦éš›çš„è­‰åˆ¸ä»£è™Ÿæ˜¯æ•¸å­—ï¼Œè€Œå‚™è¨»è¡Œçš„ç¬¬ä¸€å€‹æ¬„ä½é€šå¸¸æ˜¯èªªæ˜æ–‡å­—ã€‚

å¥½çš„ï¼Œæˆ‘å·²ç¶“ä¿®æ”¹äº† clean_data å‡½å¼ï¼Œè®“å®ƒåœ¨è™•ç†è³‡æ–™æ™‚æœƒéæ¿¾æ‰ç¬¬ä¸€å€‹æ¬„ä½ä¸æ˜¯æ•¸å­—çš„è¡Œã€‚

ç¾åœ¨ï¼Œæˆ‘å€‘éœ€è¦é‡æ–°åŸ·è¡Œä¸‹è¼‰å’Œåˆä½µè³‡æ–™çš„ç¨‹å¼ç¢¼ï¼Œè®“æ–°çš„ clean_data å‡½å¼ç”Ÿæ•ˆã€‚åŸ·è¡Œå®Œæˆå¾Œï¼Œæˆ‘å€‘æœƒå†æ¬¡ä½¿ç”¨ df_combined.info() ä¾†ç¢ºèªåˆä½µå¾Œçš„ DataFrame ä¸­æ˜¯å¦å·²ç¶“ç§»é™¤äº†é‚£äº›å‚™è¨»è¡Œã€‚

ä½ å·²åœæ­¢é€™å‰‡å›è¦†

date = "20250702" raw_text = download_twse_csv(date) lines = extract_csv_lines(raw_text) header_line, data_lines = find_data_section(lines) df = clean_data(header_line, data_lines) df.head().tail() åœ¨é€™é‚Šï¼Œæˆ‘è©²å¦‚ä½•åŒæ™‚è¼¸å‡ºhead()å’Œtail()
å¥½çš„ï¼Œæ‚¨æƒ³è¦åœ¨åŒä¸€å€‹è¼¸å‡ºä¸­çœ‹åˆ° DataFrame çš„é–‹é ­å¹¾è¡Œ (head()) å’Œçµå°¾å¹¾è¡Œ (tail())ã€‚

ä½¿ç”¨ df.head().tail() æ˜¯ä¸æ­£ç¢ºçš„ï¼Œå› ç‚º df.head() å·²ç¶“åªåŒ…å«é–‹é ­çš„å¹¾è¡Œï¼Œå†å°é€™å¹¾è¡Œå– tail() å¯èƒ½æœƒå¾—åˆ°ç©ºçµæœæˆ–éé æœŸçš„è¼¸å‡ºã€‚

åœ¨ Colab ä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ display() å‡½å¼ä¾†é¡¯ç¤ºå¤šå€‹è®Šæ•¸æˆ–è¡¨é”å¼çš„è¼¸å‡ºã€‚

æˆ‘å°‡ä¿®æ”¹æ‚¨çš„ç¨‹å¼ç¢¼ï¼Œä½¿ç”¨ display() ä¾†åŒæ™‚é¡¯ç¤º df.head() å’Œ df.tail()ã€‚

å¥½çš„ï¼Œç¾åœ¨æ‚¨å¯ä»¥åœ¨åŒä¸€å€‹è¼¸å‡ºä¸­çœ‹åˆ° DataFrame çš„é–‹é ­å’Œçµå°¾äº†ã€‚

æ‚¨ä¹‹å‰ä¹Ÿå·²ç¶“æˆåŠŸåœ°å°‡å¤šæ—¥çš„è‚¡ç¥¨è³‡æ–™åˆä½µåˆ°äº† df_combined é€™å€‹ DataFrame ä¸­ï¼Œä¸¦ä¸”ä¿®æ”¹äº† clean_data å‡½å¼ä¾†éæ¿¾æ‰å‚™è¨»è¡Œã€‚

æ¥ä¸‹ä¾†ï¼Œæ‚¨å¯èƒ½æƒ³è¦æŸ¥çœ‹ä¸€ä¸‹åˆä½µå¾Œçš„ df_combined é€™å€‹ DataFrame çš„é–‹é ­å’Œçµå°¾ï¼Œä¾†ç¢ºèªè³‡æ–™çš„çµæ§‹å’Œå…§å®¹æ˜¯å¦ç¬¦åˆé æœŸã€‚

å¥½çš„ï¼Œæˆ‘å€‘å·²ç¶“æˆåŠŸä¸‹è¼‰äº† 2024 å¹´ 6 æœˆ 30 æ—¥è‡³ 2024 å¹´ 7 æœˆ 4 æ—¥æœŸé–“çš„è‡ºç£è­‰åˆ¸äº¤æ˜“æ‰€æ¯æ—¥æ”¶ç›¤è¡Œæƒ…è³‡æ–™ï¼Œå°‡å…¶åˆä½µåˆ°ä¸€å€‹ä¹¾æ·¨çš„ pandas DataFrame df_combined ä¸­ï¼Œä¸¦ä¸”ç§»é™¤äº†å‚™è¨»è¡Œã€‚æˆ‘å€‘ä¹ŸæŸ¥çœ‹äº†åˆä½µå¾Œ DataFrame çš„é–‹é ­å’Œçµå°¾ï¼Œä»¥åŠå®ƒçš„è³‡è¨Šã€‚

æ ¹æ“šæ‚¨æœ€åˆçš„è¦æ±‚ï¼Œç¾åœ¨éœ€è¦æä¾›ç›¸é—œçš„åˆ†äº«é€£çµï¼š

Colab åˆ†äº«é€£çµ: æ‚¨å¯ä»¥å¾ç€è¦½å™¨é ‚éƒ¨çš„åˆ†äº«æŒ‰éˆ•ç²å– Colab ç­†è¨˜æœ¬çš„åˆ†äº«é€£çµã€‚è«‹ç¢ºä¿åˆ†äº«è¨­å®šå…è¨±æˆ‘æŸ¥çœ‹ã€‚
HackMD é€£çµ (å¦‚æœä½¿ç”¨ VS Code): å¦‚æœæ‚¨æ˜¯åœ¨ VS Code ä¸­å®Œæˆçš„ï¼Œè«‹å°‡ç¨‹å¼ç¢¼å’ŒåŸ·è¡Œçµæœæ•´ç†åˆ° HackMD æ–‡ä»¶ä¸­ï¼Œä¸¦æä¾›è©²æ–‡ä»¶çš„åˆ†äº«é€£çµã€‚
èŠå¤©æ©Ÿå™¨äººå°è©±ç´€éŒ„åˆ†äº«é€£çµ: æ‚¨å¯ä»¥åœ¨é€™å€‹èŠå¤©ä»‹é¢ä¸­æ‰¾åˆ°åˆ†äº«å°è©±ç´€éŒ„çš„é¸é …ï¼Œä¸¦æä¾›ç›¸æ‡‰çš„é€£çµã€‚
è«‹æä¾›é€™äº›é€£çµä»¥ä¾¿æˆ‘ç¢ºèªä»»å‹™çš„æœ€çµ‚å®Œæˆç‹€æ…‹ã€‚

å¦‚æœæ‚¨é‚„æœ‰å…¶ä»–çš„åˆ†ææˆ–è™•ç†éœ€æ±‚ï¼Œä¹Ÿè«‹éš¨æ™‚å‘Šè¨´æˆ‘ï¼

ä»»å‹™å·²å®Œæˆã€‚


ç‚ºä»€éº¼æœ€å¾Œå°å‡ºçš„dataframeæ˜¯å¾å°ç£æ°´æ³¥é–‹å§‹(è‚¡ç¥¨)ï¼Œè€Œéè­‰åˆ¸?
æ‚¨å¥½ï¼Œæ‚¨çœ‹åˆ°çš„ DataFrame è¼¸å‡ºæ˜¯å¾ 'å°æ³¥' é–‹å§‹ï¼Œæ˜¯å› ç‚º 'å°æ³¥' (è­‰åˆ¸ä»£è™Ÿ 1101) æ˜¯å¯¦éš›æ•¸æ“šä¸­çš„ç¬¬ä¸€ç­†è‚¡ç¥¨è¨˜éŒ„ã€‚

åœ¨é¡¯ç¤º DataFrame æ™‚ï¼Œç¬¬ä¸€è¡Œé€šå¸¸æ˜¯æ¬„ä½åç¨± (column headers)ï¼Œä¾‹å¦‚ 'è­‰åˆ¸ä»£è™Ÿ'ã€'è­‰åˆ¸åç¨±'ã€'æ—¥æœŸ' ç­‰ã€‚é€™äº›æ¬„ä½åç¨±ç”¨ä¾†æè¿°æ¯ä¸€åˆ—æ•¸æ“šä»£è¡¨çš„æ„ç¾©ã€‚

è€Œç·Šéš¨å…¶å¾Œçš„è¡Œæ‰æ˜¯å¯¦éš›çš„æ•¸æ“šè¨˜éŒ„ (data rows)ã€‚åœ¨æ‚¨ä¸‹è¼‰çš„ TWSE æ¯æ—¥æ”¶ç›¤è¡Œæƒ…è³‡æ–™ä¸­ï¼Œç¬¬ä¸€ç­†æ•¸æ“šè¨˜éŒ„çš„è­‰åˆ¸ä»£è™Ÿæ˜¯ '1101'ï¼Œå°æ‡‰çš„è­‰åˆ¸åç¨±æ˜¯ 'å°æ³¥'ã€‚

æ‰€ä»¥ï¼Œæ‚¨çœ‹åˆ°çš„è¼¸å‡ºæ˜¯æ­£ç¢ºçš„ï¼Œå®ƒé¡¯ç¤ºäº† DataFrame çš„æ¬„ä½åç¨±ï¼Œä»¥åŠå¾ç¬¬ä¸€ç­†æ•¸æ“šè¨˜éŒ„ ('å°æ³¥') é–‹å§‹çš„å…§å®¹ã€‚'è­‰åˆ¸ä»£è™Ÿ' å’Œ 'è­‰åˆ¸åç¨±' æ˜¯æ¬„ä½çš„æ¨™é¡Œï¼Œè€Œä¸æ˜¯ç¬¬ä¸€ç­†æ•¸æ“šæœ¬èº«ã€‚

å¸Œæœ›é€™æ¨£è§£é‡‹æœ‰å¹«åŠ©ï¼å¦‚æœæ‚¨é‚„æœ‰å…¶ä»–å•é¡Œï¼Œè«‹éš¨æ™‚æå‡ºã€‚


èˆŠå¼æˆ‘æƒ³è¦è­‰åˆ¸çš„è³‡æ–™ä¸€èµ·è®€å…¥ï¼Œæ‰€ä»¥åœ¨åˆ¤æ–·å½¢æˆä¹¾æ·¨çš„dataframeéç¨‹ä¼¼ä¹å‡ºç¾å•é¡Œ
å¥½çš„ï¼Œæˆ‘äº†è§£äº†ã€‚æ‚¨æ˜¯å¸Œæœ›åœ¨ç”Ÿæˆä¹¾æ·¨çš„ DataFrame æ™‚ï¼Œä¸è¦éæ¿¾æ‰é‚£äº›åŒ…å«ã€Œè­‰åˆ¸ã€æˆ–å…¶ä»–éæ•¸å­—é–‹é ­çš„è³‡æ–™è¡Œï¼Œé€™æ¨£æ‚¨å¯ä»¥çœ‹åˆ°åŸå§‹ CSV ä¸­çš„æ‰€æœ‰å…§å®¹ï¼ŒåŒ…æ‹¬è¡¨é ­å’Œå‚™è¨»ã€‚

ç›®å‰çš„ clean_data å‡½å¼æœƒæª¢æŸ¥æ¯ä¸€è¡Œçš„ç¬¬ä¸€å€‹æ¬„ä½æ˜¯å¦ç‚ºæ•¸å­—ï¼Œå¦‚æœä¸æ˜¯ï¼Œå°±è·³éè©²è¡Œã€‚é€™å°±æ˜¯ç‚ºä»€éº¼æ‚¨çœ‹ä¸åˆ°ã€Œè­‰åˆ¸ã€ç­‰éè‚¡ç¥¨æ•¸æ“šçš„è¡Œã€‚

ç‚ºäº†é”æˆæ‚¨çš„ç›®æ¨™ï¼Œæˆ‘æœƒä¿®æ”¹ clean_data å‡½å¼ï¼Œç§»é™¤é€™å€‹æ ¹æ“šç¬¬ä¸€å€‹æ¬„ä½æ˜¯å¦ç‚ºæ•¸å­—ä¾†éæ¿¾è¡Œçš„é‚è¼¯ã€‚é€™æ¨£ï¼Œå‡½å¼å°±æœƒå°‡æ‰€æœ‰å¾ data_lines å‚³å…¥çš„è¡Œéƒ½å˜—è©¦è½‰æ›ç‚º DataFrame çš„ä¸€éƒ¨åˆ†ã€‚

è«‹æ³¨æ„ï¼Œç§»é™¤é€™å€‹éæ¿¾å¾Œï¼ŒDataFrame ä¸­å°‡æœƒåŒ…å«è¡¨é ­ä»¥ä¸‹çš„æ‰€æœ‰è¡Œï¼ŒåŒ…æ‹¬å¯¦éš›æ•¸æ“šã€å‚™è¨»å’Œå¯èƒ½çš„å…¶ä»–éæ•¸æ“šè¡Œã€‚æ‚¨å¯èƒ½éœ€è¦å¾ŒçºŒæ­¥é©Ÿä¾†è™•ç†æˆ–è­˜åˆ¥é€™äº›éæ•¸æ“šè¡Œã€‚


def clean_data(header_line: str, data_lines: list) -> pd.DataFrame: ''' Convert header and data lines to a cleaned DataFrame. Removes specific characters but includes all provided data lines. ''' header = next(csv.reader([header_line])) rows = list(csv.reader(data_lines)) cleaned_rows = [] for row in rows: # Removed filtering based on the first column being a digit cleaned_row = [ cell.replace('="', '').replace('"', '').strip() if cell.startswith('="') else cell.replace('"', '').strip() for cell in row ] # Ensure the cleaned row has the same number of columns as the header if len(cleaned_row) == len(header): cleaned_rows.append(cleaned_row) else: print(f"âš ï¸ Skipping row due to column count mismatch: {row}") # Optional: print skipped rows df = pd.DataFrame(cleaned_rows, columns=header) print(f"âœ… Created DataFrame with shape {df.shape}") return df åŒ…æˆ‘é€è¡Œè§£é‡‹
å¥½çš„ï¼Œé€™æ®µç¨‹å¼ç¢¼æ˜¯ä¿®æ”¹å¾Œçš„ clean_data å‡½å¼ï¼Œå®ƒç¾åœ¨æœƒå°‡æ‰€æœ‰å‚³å…¥çš„è³‡æ–™è¡Œéƒ½å˜—è©¦è½‰æ›ç‚º DataFrameï¼ŒåŒæ™‚é€²è¡Œå­—å…ƒæ¸…ç†ã€‚

ä»¥ä¸‹æ˜¯é€è¡Œè§£é‡‹ï¼š

def clean_data(header_line: str, data_lines: list) -> pd.DataFrame:: é€™ä¸€è¡Œå®šç¾©äº†å‡½å¼ clean_dataï¼Œåƒæ•¸å’Œå›å‚³å€¼å‹åˆ¥æç¤ºèˆ‡ä¹‹å‰ç›¸åŒã€‚
header_line: str: åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹å­—ä¸²ï¼Œä»£è¡¨è¡¨é ­è¡Œã€‚
data_lines: list: åƒæ•¸ï¼Œé æœŸæ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹å­—ä¸²ï¼Œä»£è¡¨è³‡æ–™è¡Œã€‚
-> pd.DataFrame: å‹åˆ¥æç¤ºï¼Œè¡¨ç¤ºå‡½å¼é æœŸå›å‚³ä¸€å€‹ pandas DataFrame ç‰©ä»¶ã€‚
''' ... ''': å‡½å¼çš„èªªæ˜æ–‡ä»¶ (docstring)ã€‚æ›´æ–°å¾Œçš„èªªæ˜æŒ‡å‡ºå‡½å¼æœƒç§»é™¤ç‰¹å®šå­—å…ƒï¼Œä½†åŒ…å«æ‰€æœ‰æä¾›çš„è³‡æ–™è¡Œã€‚
header = next(csv.reader([header_line])): é€™ä¸€è¡Œèˆ‡ä¹‹å‰ç›¸åŒï¼Œè™•ç†è¡¨é ­è¡Œï¼Œä½¿ç”¨ csv.reader è§£æå¾Œï¼Œå–å‡ºç¬¬ä¸€å€‹çµæœä½œç‚º DataFrame çš„æ¬„ä½åç¨±åˆ—è¡¨ï¼Œå„²å­˜åœ¨ header è®Šæ•¸ä¸­ã€‚
rows = list(csv.reader(data_lines)): é€™ä¸€è¡Œä¹Ÿèˆ‡ä¹‹å‰ç›¸åŒï¼Œä½¿ç”¨ csv.reader è§£æ data_lines åˆ—è¡¨ä¸­çš„æ¯ä¸€å€‹å­—ä¸² (æ¯ä¸€è¡Œ)ï¼Œå°‡çµæœè½‰æ›ç‚ºä¸€å€‹åˆ—è¡¨ rowsã€‚rows æ˜¯ä¸€å€‹åˆ—è¡¨çš„åˆ—è¡¨ï¼Œå¤–å±¤åˆ—è¡¨ä»£è¡¨è¡Œï¼Œå…§å±¤åˆ—è¡¨ä»£è¡¨è©²è¡Œçš„æ¬„ä½å€¼ã€‚
cleaned_rows = []: åˆå§‹åŒ–ä¸€å€‹ç©ºçš„åˆ—è¡¨ cleaned_rowsï¼Œç”¨æ–¼å„²å­˜æ¸…ç†å¾Œçš„è³‡æ–™è¡Œã€‚
for row in rows:: éæ­· rows åˆ—è¡¨ä¸­æ¯ä¸€è¡Œ (æ¯å€‹ row æ˜¯ä¸€å€‹æ¬„ä½å€¼çš„åˆ—è¡¨)ã€‚
# Removed filtering based on the first column being a digit: é€™æ˜¯ä¸€è¡Œè¨»è§£ï¼Œèªªæ˜ä¹‹å‰æ ¹æ“šç¬¬ä¸€å€‹æ¬„ä½æ˜¯å¦ç‚ºæ•¸å­—é€²è¡Œéæ¿¾çš„ç¨‹å¼ç¢¼å·²ç¶“è¢«ç§»é™¤ã€‚
cleaned_row = [...]: é€™æ˜¯ä¸€å€‹åˆ—è¡¨æ¨å°å¼ï¼Œç”¨æ–¼è™•ç†ç•¶å‰è¡Œçš„æ¯ä¸€å€‹æ¬„ä½ã€‚
for cell in row: éæ­·ç•¶å‰è¡Œ row ä¸­çš„æ¯ä¸€å€‹æ¬„ä½å€¼ (cell)ã€‚
cell.replace('="', '').replace('"', '').strip(): å°æ¯ä¸€å€‹æ¬„ä½å€¼é€²è¡Œå­—ä¸²æ›¿æ›å’Œå»é™¤ç©ºç™½æ“ä½œã€‚
cell.replace('="', ''): æ›¿æ›æ‰é–‹é ­çš„ ="ã€‚
.replace('"', ''): æ›¿æ›æ‰æ‰€æœ‰çš„é›™å¼•è™Ÿ "ã€‚
.strip(): ç§»é™¤å­—ä¸²é–‹é ­å’Œçµå°¾çš„ç©ºç™½å­—å…ƒã€‚
if cell.startswith('="') else cell.replace('"', '').strip(): é€™æ˜¯ä¸€å€‹æ¢ä»¶è¡¨é”å¼ï¼Œèˆ‡ä¹‹å‰ç›¸åŒï¼Œç”¨æ–¼è™•ç†å¯èƒ½ä»¥ =" é–‹é ­çš„æ¬„ä½å€¼ï¼Œç¢ºä¿ç§»é™¤é›™å¼•è™Ÿå’Œç©ºç™½ã€‚
è™•ç†å¾Œçš„æ¯ä¸€å€‹æ¬„ä½å€¼çµ„æˆä¸€å€‹æ–°çš„åˆ—è¡¨ cleaned_rowã€‚
# Ensure the cleaned row has the same number of columns as the header: è¨»è§£ï¼Œèªªæ˜æ¥ä¸‹ä¾†çš„æª¢æŸ¥æ˜¯ç‚ºäº†ç¢ºä¿è³‡æ–™è¡Œçš„æ¬„ä½æ•¸é‡èˆ‡è¡¨é ­ä¸€è‡´ã€‚
if len(cleaned_row) == len(header):: æª¢æŸ¥æ¸…ç†å¾Œçš„ç•¶å‰è¡Œ cleaned_row çš„æ¬„ä½æ•¸é‡æ˜¯å¦èˆ‡è¡¨é ­ header çš„æ¬„ä½æ•¸é‡ç›¸åŒã€‚
cleaned_rows.append(cleaned_row): å¦‚æœæ¬„ä½æ•¸é‡åŒ¹é…ï¼Œå‰‡å°‡æ¸…ç†å¾Œçš„ cleaned_row æ·»åŠ åˆ° cleaned_rows åˆ—è¡¨ä¸­ã€‚é€™äº›è¡Œå°‡è¢«ç”¨ä¾†å‰µå»º DataFrameã€‚
else:: å¦‚æœæ¬„ä½æ•¸é‡ä¸åŒ¹é…ã€‚
print(f"âš ï¸ Skipping row due to column count mismatch: {row}") # Optional: print skipped rows: å°å‡ºä¸€æ¢è­¦å‘Šè¨Šæ¯ï¼Œèªªæ˜ç”±æ–¼æ¬„ä½æ•¸é‡ä¸åŒ¹é…è€Œè·³éäº†é€™ä¸€è¡Œï¼Œä¸¦é¡¯ç¤ºåŸå§‹çš„ row å…§å®¹ã€‚é€™æœ‰åŠ©æ–¼é™¤éŒ¯ï¼Œäº†è§£å“ªäº›è¡Œå› ç‚ºæ ¼å¼å•é¡Œè¢«å¿½ç•¥äº†ã€‚
df = pd.DataFrame(cleaned_rows, columns=header): ä½¿ç”¨ç¬¦åˆæ¬„ä½æ•¸é‡åŒ¹é…çš„ cleaned_rows åˆ—è¡¨å’Œè¡¨é ­åˆ—è¡¨ header ä¾†å‰µå»ºä¸€å€‹ pandas DataFrameï¼Œä¸¦å°‡çµæœè³¦å€¼çµ¦ df è®Šæ•¸ã€‚
print(f"âœ… Created DataFrame with shape {df.shape}"): å°å‡ºä¸€æ¢è¨Šæ¯ï¼Œé¡¯ç¤ºæˆåŠŸå‰µå»ºäº† DataFrameï¼Œä¸¦é¡¯ç¤ºå…¶å½¢ç‹€ (åˆ—æ•¸, æ¬„æ•¸)ã€‚
return df: å‡½å¼å›å‚³æœ€çµ‚å‰µå»ºä¸¦æ¸…ç†å¥½çš„ pandas DataFrameã€‚
èˆ‡ä¹‹å‰ç‰ˆæœ¬çš„ä¸»è¦å€åˆ¥åœ¨æ–¼ï¼Œé€™å€‹ç‰ˆæœ¬ä¸å†æª¢æŸ¥ç¬¬ä¸€æ¬„æ˜¯å¦ç‚ºæ•¸å­—ä¾†éæ¿¾è¡Œï¼Œè€Œæ˜¯å˜—è©¦è™•ç†æ‰€æœ‰å‚³å…¥çš„ data_linesï¼Œåªæœƒå› ç‚ºæ¬„ä½æ•¸é‡èˆ‡è¡¨é ­ä¸åŒ¹é…è€Œè·³éæŸäº›è¡Œã€‚é€™è®“æ‚¨å¯ä»¥å°‡åŸå§‹ CSV ä¸­è¡¨é ­å¾Œçš„æ‰€æœ‰è¡Œéƒ½è®€å…¥ DataFrame ä¸­ã€‚


if len(cleaned_row) == len(header): cleaned_rows.append(cleaned_row) else: #print(f"âš ï¸ Skipping row due to column count mismatch: {row}") # Optional: print skipped rows å¦‚æœä¸åŒ¹é…å°±ç›´æ¥è·³éï¼Œçœå»éœ€è¦ã€Œç§»é™¤é€™å€‹éæ¿¾å¾Œï¼ŒDataFrame ä¸­å°‡æœƒåŒ…å«è¡¨é ­ä»¥ä¸‹çš„æ‰€æœ‰è¡Œï¼ŒåŒ…æ‹¬å¯¦éš›æ•¸æ“šã€å‚™è¨»å’Œå¯èƒ½çš„å…¶ä»–éæ•¸æ“šè¡Œã€‚æ‚¨å¯èƒ½éœ€è¦å¾ŒçºŒæ­¥é©Ÿä¾†è™•ç†æˆ–è­˜åˆ¥é€™äº›éæ•¸æ“šè¡Œã€‚ã€
æ‚¨èªªå¾—å¾ˆå°ï¼

ä¿®æ”¹å¾Œçš„ clean_data å‡½å¼ä¸­ä¿ç•™äº†é€™å€‹æ¢ä»¶ï¼š

if len(cleaned_row) == len(header):
    cleaned_rows.append(cleaned_row)
else:
    # Skipping row due to column count mismatch
    pass # æˆ– print è­¦å‘Š
é€™å€‹ if len(cleaned_row) == len(header): çš„æª¢æŸ¥ç¢ºå¯¦æ˜¯ä¸€ç¨®éæ¿¾ã€‚å®ƒæœƒç¢ºä¿åªæœ‰æ¬„ä½æ•¸é‡èˆ‡è¡¨é ­ä¸€è‡´çš„è¡Œæ‰æœƒè¢«æ·»åŠ åˆ° cleaned_rows åˆ—è¡¨ä¸­ï¼Œé€²è€ŒåŒ…å«åœ¨æœ€çµ‚çš„ DataFrame ä¸­ã€‚

å°æ–¼ TWSE æä¾›çš„ CSV æª”æ¡ˆï¼Œè¨±å¤šä½æ–¼è³‡æ–™å€æ®µä¹‹å¾Œçš„å‚™è¨»è¡Œæˆ–èªªæ˜è¡Œï¼Œå®ƒå€‘çš„çµæ§‹å¯èƒ½èˆ‡å¯¦éš›çš„æ•¸æ“šè¡Œä¸åŒï¼Œå°è‡´æ¬„ä½æ•¸é‡ä¸åŒ¹é…ã€‚å› æ­¤ï¼Œé€™å€‹æ ¹æ“šæ¬„ä½æ•¸é‡é€²è¡Œçš„éæ¿¾ï¼Œç¢ºå¯¦å¯ä»¥å¹«åŠ©æ‚¨æ’é™¤æ‰ä¸€éƒ¨åˆ†æ ¼å¼ä¸ç¬¦çš„éæ•¸æ“šè¡Œï¼ŒåŒ…æ‹¬ä¸€äº›å‚™è¨»ã€‚

é€™èˆ‡ä¹‹å‰åŸºæ–¼ã€Œç¬¬ä¸€å€‹æ¬„ä½æ˜¯å¦ç‚ºæ•¸å­—ã€çš„éæ¿¾æ–¹å¼ä¸åŒï¼Œä½†éƒ½èƒ½èµ·åˆ°æ’é™¤éƒ¨åˆ†éæ•¸æ“šè¡Œçš„ä½œç”¨ã€‚

æ‚¨è§€å¯Ÿå¾—å¾ˆæº–ç¢ºï¼Œä¾é æ¬„ä½æ•¸é‡çš„åŒ¹é…ä¾†éæ¿¾ï¼Œåœ¨æŸäº›æƒ…æ³ä¸‹ï¼Œç¢ºå¯¦å¯ä»¥æ¸›å°‘éœ€è¦æ‰‹å‹•è™•ç†æˆ–è­˜åˆ¥çš„éæ•¸æ“šè¡Œã€‚

ä¸éè«‹æ³¨æ„ï¼Œå¦‚æœæŸäº›å‚™è¨»è¡Œæˆ–éæ•¸æ“šè¡Œæ°å¥½ä¹ŸåŒ…å«èˆ‡è¡¨é ­ç›¸åŒæ•¸é‡çš„æ¬„ä½ï¼Œé‚£éº¼é€™å€‹éæ¿¾æ¢ä»¶å°±ç„¡æ³•å°‡å®ƒå€‘æ’é™¤æ‰ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œæ‚¨ä»ç„¶éœ€è¦åœ¨ç”Ÿæˆ DataFrame å¾Œï¼Œæ ¹æ“šå…¶ä»–ç‰¹å¾µ (ä¾‹å¦‚æ¬„ä½çš„å…§å®¹æ˜¯å¦ç‚ºæ•¸å­—æˆ–ç‰¹å®šæ–‡å­—) ä¾†é€²ä¸€æ­¥ç¯©é¸æˆ–æ¸…ç†ã€‚

ä½†å°æ–¼å¤§å¤šæ•¸ TWSE çš„å‚™è¨»è¡Œï¼Œæ¬„ä½æ•¸é‡ä¸åŒ¹é…æ˜¯ä¸€å€‹å¸¸è¦‹çš„ç‰¹å¾µï¼Œæ‰€ä»¥æ‚¨ç¾åœ¨çš„ç¨‹å¼ç¢¼æ‡‰è©²å·²ç¶“èƒ½æ’é™¤æ‰å¤§éƒ¨åˆ†çš„å‚™è¨»äº†ã€‚

æ‚¨çš„ç†è§£æ˜¯æ­£ç¢ºçš„ï¼Œä¾é é€™å€‹æ¬„ä½æ•¸é‡åŒ¹é…çš„éæ¿¾ï¼Œå¯ä»¥çœå»è™•ç†æ‰€æœ‰è¡¨é ­å¾Œè¡Œçš„æ­¥é©Ÿï¼Œåªä¿ç•™çµæ§‹ä¸Šèˆ‡æ•¸æ“šè¡Œæ›´ç›¸ä¼¼çš„è¡Œã€‚


è«‹ä¸Šå‚³ èŠå¤©æ©Ÿå™¨äººçš„å°è©±ç´€éŒ„åˆ†äº«é€£çµ æˆ‘è©²å¦‚ä½•ä¸Šå‚³é€™ä»½é€£å¤©è¨˜éŒ„é€£çµ?
å¥½çš„ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æä¾›èŠå¤©è¨˜éŒ„çš„åˆ†äº«é€£çµã€‚

åœ¨ Google Colab çš„èŠå¤©ä»‹é¢ä¸­ï¼Œæ‚¨æ‡‰è©²å¯ä»¥åœ¨ä»‹é¢çš„ä¸Šæ–¹æˆ–å´é‚Šæ‰¾åˆ°ä¸€å€‹é¸é …ä¾†åˆ†äº«å°è©±è¨˜éŒ„ã€‚

é€šå¸¸é€™å€‹é¸é …æœƒæ˜¯ä¸€å€‹æŒ‰éˆ•æˆ–åœ–æ¨™ï¼Œé»æ“Šå¾Œæœƒç”Ÿæˆä¸€å€‹åˆ†äº«é€£çµï¼Œæ‚¨å¯ä»¥è¤‡è£½é€™å€‹é€£çµæä¾›çµ¦æˆ‘ã€‚

å…·é«”çš„æ“ä½œæ­¥é©Ÿå¯èƒ½æœƒå› ç‚º Colab ä»‹é¢çš„æ›´æ–°è€Œç•¥æœ‰ä¸åŒï¼Œæ‚¨å¯ä»¥å°‹æ‰¾é¡ä¼¼ã€Œåˆ†äº«ã€ã€ã€ŒShareã€ã€ã€Œé€£çµã€ç­‰å­—æ¨£çš„æŒ‰éˆ•æˆ–èœå–®é¸é …ã€‚

å¦‚æœæ‚¨æ‰¾åˆ°äº†åˆ†äº«é¸é …ä¸¦ç”Ÿæˆäº†é€£çµï¼Œè«‹ç›´æ¥å°‡é€£çµè²¼åˆ°èŠå¤©æ¡†ä¸­å³å¯ã€‚
"""